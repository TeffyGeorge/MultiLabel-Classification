{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl3eIEYFkgP7"
      },
      "source": [
        "# <font color = 'blue'> **TASK 2**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3gTwMBqxIUS"
      },
      "source": [
        "# <font color = 'blue'> **NN with pre_trained Embeddings**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YOhpYDs1bvKn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfyZf28zDRHM"
      },
      "source": [
        "<font color = 'green'>  **Objective:**\n",
        "- Learn to use pre-trained embeddings in a Neural Network</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2nAIo5uNxEr"
      },
      "source": [
        "# <font color = 'blue'> **Specify Project Folders**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T06:35:00.477315Z",
          "iopub.status.busy": "2022-10-24T06:35:00.477121Z",
          "iopub.status.idle": "2022-10-24T06:35:00.501515Z",
          "shell.execute_reply": "2022-10-24T06:35:00.501036Z",
          "shell.execute_reply.started": "2022-10-24T06:35:00.477300Z"
        },
        "id": "zd6c5IGa_iUl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# This is the path where we will downlaod and save data\n",
        "from pathlib import Path\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  base_folder = Path('/content/drive/MyDrive/NLP')\n",
        "else:\n",
        "  base_folder = Path('/content/drive/MyDrive/NLP')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T06:35:00.851696Z",
          "iopub.status.busy": "2022-10-24T06:35:00.851458Z",
          "iopub.status.idle": "2022-10-24T06:35:00.877740Z",
          "shell.execute_reply": "2022-10-24T06:35:00.877168Z",
          "shell.execute_reply.started": "2022-10-24T06:35:00.851659Z"
        },
        "id": "Z0yKILuteTDE",
        "tags": []
      },
      "outputs": [],
      "source": [
        "custom_functions =  base_folder/'data/customfiles'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T06:35:01.177121Z",
          "iopub.status.busy": "2022-10-24T06:35:01.176886Z",
          "iopub.status.idle": "2022-10-24T06:35:01.202137Z",
          "shell.execute_reply": "2022-10-24T06:35:01.201556Z",
          "shell.execute_reply.started": "2022-10-24T06:35:01.177106Z"
        },
        "id": "1i9tdWEkOha8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(str(custom_functions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T06:35:01.529413Z",
          "iopub.status.busy": "2022-10-24T06:35:01.529235Z",
          "iopub.status.idle": "2022-10-24T06:35:01.554874Z",
          "shell.execute_reply": "2022-10-24T06:35:01.554354Z",
          "shell.execute_reply.started": "2022-10-24T06:35:01.529399Z"
        },
        "id": "m8C6e11FOiEX",
        "outputId": "ceb9589b-b237-4684-ec96-4e41aad8f506",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python37.zip',\n",
              " '/usr/lib/python3.7',\n",
              " '/usr/lib/python3.7/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.7/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/content/drive/MyDrive/NLP/data/customfiles']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "sys.path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IPYN_5KW9Di"
      },
      "source": [
        "# <font color = 'blue'>  Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "yVD-gx74RLUe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  print('Running on CoLab')\n",
        "else:\n",
        "  print('Not running on CoLab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9w5IaxSRMEs",
        "outputId": "1d80c655-227e-43c5-eaaf-d5118e11a8dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CoLab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHBvJv4kiO0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56098d5c-2b5e-4a17-87fc-0b53d12a0140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 24.1 MB 19.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  !pip install --upgrade gensim -qq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  !pip install wandb --upgrade"
      ],
      "metadata": {
        "id": "ZFlt-2cQYJhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05bd803e-3c90-457b-d46b-ba069a5f9aa6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.5-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 13.9 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.19.6)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.11.0-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 58.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 54.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 50.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 50.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 27.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 54.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 54.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 14.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 59.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 61.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 53.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 68.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 10.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 55.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=df94becf4248861d0589c52b613cc855c20ef47824c7a181c4975ed54ff8c742\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 wandb-0.13.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-AzQLmTVmp_",
        "outputId": "28df771f-b0c7-4e2a-e16a-4621e2e40b01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "E__2oxC7W9Dj"
      },
      "outputs": [],
      "source": [
        "# Import random function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.vocab import  vocab\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, StepLR\n",
        "\n",
        "import wandb\n",
        "import spacy\n",
        "#import custom_preprocessor as cp\n",
        "\n",
        "import random\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from collections import Counter\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from types import SimpleNamespace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "T2U_UUYmiY6I",
        "outputId": "248b143b-fd72-4322-845f-4688d6a43bf2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.2.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "gensim.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "06f2H4UiW9Dj"
      },
      "outputs": [],
      "source": [
        "data_folder = base_folder/'Homework6/datasets'\n",
        "save_model_folder = base_folder/'Homework6/models'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0CyZzobQoT_"
      },
      "source": [
        "We will be using W&B for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "faY9UaHhQkb3",
        "outputId": "62185b5d-025b-4138-94a3-9b31235a6d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Login to W&B\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTrbf15aROgj"
      },
      "source": [
        "## <font color = 'blue'> Train/Test/Valid Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2f94n6S-6YCO"
      },
      "outputs": [],
      "source": [
        "df = joblib.load(data_folder/'df_multilabel_hw_cleaned.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "gBJ59u1-dn9H",
        "outputId": "7c8bb517-8073-41c5-9584-729e69cf868d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1       Id  \\\n",
              "0       35264       3589944  3589945   \n",
              "1       56592       5756414  5756415   \n",
              "2       23303       2358596  2358597   \n",
              "3       42563       4332881  4332882   \n",
              "4       58216       5922132  5922133   \n",
              "\n",
              "                                               Title  \\\n",
              "0                     ASP Query String From DropDown   \n",
              "1  How can I run JavaScript code at server side J...   \n",
              "2  linq to sql throwing an exception row not foun...   \n",
              "3            Running a Python script on a PHP server   \n",
              "4  some advice on how to write a window.resize fu...   \n",
              "\n",
              "                                                Body               Tags  \\\n",
              "0  <p>I have a webpage: <strong>Menu.aspx</strong...         c# asp.net   \n",
              "1  <p>I want to run JavaScript code at the server...    java javascript   \n",
              "2  <p>Hi I am linq to sql and i am getting the er...         c# asp.net   \n",
              "3  <p>I am running a nginx web server, along with...         php python   \n",
              "4  <p>Im trying to write a function that resizes ...  javascript jquery   \n",
              "\n",
              "  Tag_Number                                      combined_text  \\\n",
              "0     [0, 9]  ASP Query String From DropDown <p>I have a web...   \n",
              "1     [1, 3]  How can I run JavaScript code at server side J...   \n",
              "2     [0, 9]  linq to sql throwing an exception row not foun...   \n",
              "3     [2, 7]  Running a Python script on a PHP server <p>I a...   \n",
              "4     [3, 5]  some advice on how to write a window.resize fu...   \n",
              "\n",
              "                     cleaned_text_lemma_stop_removal  \n",
              "0  asp query string dropdown webpage following co...  \n",
              "1  run javascript code server java code want run ...  \n",
              "2  linq sql throw exception row find change hi li...  \n",
              "3  run python script php server run nginx web ser...  \n",
              "4  advice write function m try write function res...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e9bfc36-6fd1-479d-af7b-bb2be88d99eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "      <th>Tag_Number</th>\n",
              "      <th>combined_text</th>\n",
              "      <th>cleaned_text_lemma_stop_removal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35264</td>\n",
              "      <td>3589944</td>\n",
              "      <td>3589945</td>\n",
              "      <td>ASP Query String From DropDown</td>\n",
              "      <td>&lt;p&gt;I have a webpage: &lt;strong&gt;Menu.aspx&lt;/strong...</td>\n",
              "      <td>c# asp.net</td>\n",
              "      <td>[0, 9]</td>\n",
              "      <td>ASP Query String From DropDown &lt;p&gt;I have a web...</td>\n",
              "      <td>asp query string dropdown webpage following co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56592</td>\n",
              "      <td>5756414</td>\n",
              "      <td>5756415</td>\n",
              "      <td>How can I run JavaScript code at server side J...</td>\n",
              "      <td>&lt;p&gt;I want to run JavaScript code at the server...</td>\n",
              "      <td>java javascript</td>\n",
              "      <td>[1, 3]</td>\n",
              "      <td>How can I run JavaScript code at server side J...</td>\n",
              "      <td>run javascript code server java code want run ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23303</td>\n",
              "      <td>2358596</td>\n",
              "      <td>2358597</td>\n",
              "      <td>linq to sql throwing an exception row not foun...</td>\n",
              "      <td>&lt;p&gt;Hi I am linq to sql and i am getting the er...</td>\n",
              "      <td>c# asp.net</td>\n",
              "      <td>[0, 9]</td>\n",
              "      <td>linq to sql throwing an exception row not foun...</td>\n",
              "      <td>linq sql throw exception row find change hi li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42563</td>\n",
              "      <td>4332881</td>\n",
              "      <td>4332882</td>\n",
              "      <td>Running a Python script on a PHP server</td>\n",
              "      <td>&lt;p&gt;I am running a nginx web server, along with...</td>\n",
              "      <td>php python</td>\n",
              "      <td>[2, 7]</td>\n",
              "      <td>Running a Python script on a PHP server &lt;p&gt;I a...</td>\n",
              "      <td>run python script php server run nginx web ser...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>58216</td>\n",
              "      <td>5922132</td>\n",
              "      <td>5922133</td>\n",
              "      <td>some advice on how to write a window.resize fu...</td>\n",
              "      <td>&lt;p&gt;Im trying to write a function that resizes ...</td>\n",
              "      <td>javascript jquery</td>\n",
              "      <td>[3, 5]</td>\n",
              "      <td>some advice on how to write a window.resize fu...</td>\n",
              "      <td>advice write function m try write function res...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e9bfc36-6fd1-479d-af7b-bb2be88d99eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e9bfc36-6fd1-479d-af7b-bb2be88d99eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e9bfc36-6fd1-479d-af7b-bb2be88d99eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9RFTtWvX7Vwr"
      },
      "outputs": [],
      "source": [
        "X = df['cleaned_text_lemma_stop_removal'].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Tag_Number'].values"
      ],
      "metadata": {
        "id": "Yx4CFiRjdm-L"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "a8sZ605P7mON"
      },
      "outputs": [],
      "source": [
        "# import swifter\n",
        "from ast import literal_eval\n",
        "df['Tag_Number_list'] = df['Tag_Number'].apply(lambda x: literal_eval(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AMapwMp88dBO"
      },
      "outputs": [],
      "source": [
        "y_final = df['Tag_Number_list'].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer as mlb"
      ],
      "metadata": {
        "id": "LxIDa8mId6VN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_one_hot = mlb().fit_transform(y_final)"
      ],
      "metadata": {
        "id": "rtrvsizfd83N"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkdP3qjTd_ln",
        "outputId": "e1c7a693-871e-406f-86fb-54e10b9ca535"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_one_hot.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zplzl-2deB8x",
        "outputId": "b54560d8-0b38-4aa1-8c3b-c2d721c142d6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47427, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid_test, y_train, y_valid_test = train_test_split(X, y_one_hot, test_size = 0.40, random_state=42)"
      ],
      "metadata": {
        "id": "2m7yEdrDeDLy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid, X_test, y_valid, y_test = train_test_split(X_valid_test, y_valid_test, test_size = 0.50, random_state=42)"
      ],
      "metadata": {
        "id": "q9mgeM5veHDA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(len(X_train), len(X_valid), len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DwlEI1UeJ7u",
        "outputId": "f9c1aa9d-858b-40aa-929d-c0b33d6f2031"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28456 9485 9486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6oR4POzeLKh",
        "outputId": "4c7b666d-ce8a-49b7-c2a0-82e57782a67f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9486,)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vxiBPx4qE9Q"
      },
      "source": [
        "## <font color = 'blue'>  Data PreProcessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE1vgu64GR_-"
      },
      "source": [
        "<font color = 'green'> We will use the preprocessed files we created earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx0-0QP48kCH",
        "outputId": "5fc387d8-8a56-4bd5-aac0-1ea6551e55e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(type(X_train))\n",
        "print(type(y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsYaM3_ftTgi"
      },
      "source": [
        "## <font color = 'blue'> Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "kFmE7lcjCuSM"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"MultiLabel dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.X = np.array(X)\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        text = self.X[idx]\n",
        "        labels = self.y[idx]\n",
        "        sample = (text, labels)\n",
        "        \n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bDesWA-Ssmk_"
      },
      "outputs": [],
      "source": [
        "trainset = CustomDataset(X_train,y_train)\n",
        "validset = CustomDataset(X_valid,y_valid)\n",
        "testset = CustomDataset(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-lZrEottGtH",
        "outputId": "dc7fc645-e7fb-4e4d-a640-ba37b6a7c7a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['code multiple button navigation java activity question 1 2 activity wonder optimize create 2 activity multiple listener create multiple java file button(onclick listener question 2 try create multiple listener java button work syntax multiple listener java file update code issue matter button click lead page      package import activity import context import intent import bundle import button import view import view onclicklistener   public class activity1 extend activity2   button button1 button button2 button button3 button button4 button button5 button button6   public void oncreate(bundle savedinstancestate      super.oncreate(savedinstancestate      setcontentview(r.layout.fineline      addlisteneronbutton      public void addlisteneronbutton   final context context =   button1 = button findviewbyid(r.id.autobody   button1.setonclicklistener(new onclicklistener        public void onclick(view arg0           intent intent = new intent(context          startactivity(intent              button2 = button findviewbyid(r.id.glass   button2.setonclicklistener(new onclicklistener       override      public void onclick(view arg0           intent intent = new intent(context          startactivity(intent              button3 = button findviewbyid(r.id.wheels   button3.setonclicklistener(new onclicklistener       override      public void onclick(view arg0           intent intent = new intent(context          startactivity(intent              button4 = button findviewbyid(r.id.speedy   button4.setonclicklistener(new onclicklistener       override      public void onclick(view arg0           intent intent = new intent(context          startactivity(intent              button5 = button findviewbyid(r.id.sevan   button5.setonclicklistener(new onclicklistener       override      public void onclick(view arg0           intent intent = new intent(context          startactivity(intent              button6 = button findviewbyid(r.id.towing button6.setonclicklistener(new onclicklistener override public void onclick(view arg0       intent intent = new intent(context      startactivity(intent              package   import activity import bundle import button   public class activity2 extend activity   button button1   public void oncreate1(bundle savedinstancestate super.oncreate(savedinstancestate setcontentview(r.layout.autobody button button2   public void oncreate2(bundle savedinstancestate super.oncreate(savedinstancestate setcontentview(r.layout.glass button button3   public void oncreate3(bundle savedinstancestate super.oncreate(savedinstancestate setcontentview(r.layout.wheel button button4   public void oncreate(bundle savedinstancestate super.oncreate(savedinstancestate setcontentview(r.layout.speedy button button5   public void oncreate5(bundle savedinstancestate super.oncreate(savedinstancestate setcontentview(r.layout.sevan   button button6   public void oncreate6(bundle savedinstancestate super.oncreate(savedinstancestate setcontentview(r.layout.towe    '],\n",
              "       dtype=object), array([[0, 1, 0, 0, 1, 0, 0, 0, 0, 0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "trainset.__getitem__([11])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEVe7eGtY7U"
      },
      "source": [
        "## <font color = 'blue'> Create Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "LRLHO-M1to6q"
      },
      "outputs": [],
      "source": [
        "def create_vocab(dataset, min_freq):\n",
        "  counter = Counter()\n",
        "  for (text, _) in dataset:\n",
        "    counter.update(str(text).split())\n",
        "  my_vocab = vocab(counter, min_freq=min_freq)\n",
        "  my_vocab.insert_token('<unk>', 0)\n",
        "  my_vocab.set_default_index(0)\n",
        "  return my_vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY5oKhQlJPQL"
      },
      "source": [
        "<font color = 'green'> vocab should always be created based on trainset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wNUi_aNctkAo"
      },
      "outputs": [],
      "source": [
        "multilabel_vocab = create_vocab(trainset, min_freq = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ask8H1QJJMZK",
        "outputId": "ab2709c9-232b-443b-ccc8-e9a3b1043825"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90235"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "len(multilabel_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eyaeFqCsuRTQ",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "483d1bab-7300-4b85-aba0-45c489db99ca",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', 'rearrange', 'order', 'list', 'web']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "multilabel_vocab.get_itos()[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDMu8-JOujxY",
        "outputId": "6c52c803-f1a0-45ff-abbf-8b658287a482"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "multilabel_vocab['teffy']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojvSMWR5u-LU"
      },
      "source": [
        "## <font color = 'blue'> Collate_fn for Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "cdBKJlVmvB-9"
      },
      "outputs": [],
      "source": [
        "# Creating a lambda function objects that will be used to get the indices of words from vocab\n",
        "text_pipeline = lambda x : [multilabel_vocab[token] for token in str(x).split()]\n",
        "vector = np.vectorize(np.int_)\n",
        "label_pipeline = lambda y : vector(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFXmxXUQw6Ei",
        "outputId": "f00c1d03-f6c5-40b0-b0fa-bad070e83761"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47427"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "cL1TZVthvIT2"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We know that input to the embedding layers are indices of words from the vocab.\n",
        "The collate_batch() accepts batch of data and gets the indices of text from vocab and returns the same\n",
        "We will include this collate_batch() in collat_fn attribute of DataLoader.\n",
        "So it will create a batch of data containing indices of words and corresponding labels.\n",
        "But for EmbeddingBag we need one more extra parameter, that is offset.\n",
        "offsets determines the starting index position of each bag (sequence) in input.\n",
        "'''\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_text, _label) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return text_list, label_list, offsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB8Kd5wCCuSN"
      },
      "source": [
        "## <font color = 'blue'> **Check Data Loader**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "qZ8DLatvCuSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4afbb731-c5fd-4674-cb7d-324278cf1406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "batch_size=2\n",
        "check_loader= torch.utils.data.DataLoader(dataset=trainset,\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=True,\n",
        "                                        collate_fn=collate_batch,\n",
        "                                        num_workers=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text, label, offsets in check_loader:\n",
        "  print(label, text, offsets)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvfeH7-BSdBJ",
        "outputId": "1e7e7811-48ed-4d8a-f912-9b114dad8bad"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1]]) tensor([16908,   425,   376,   521,    36,  1137,  1186,   460,   521,   786,\n",
            "        16909, 16908, 16910,   322,    17,   688,   786, 16909,   689,    96,\n",
            "         7543, 16911,    19,    17,   688,   786, 16909,   689, 16912,    19,\n",
            "           68,   128,  1261,  3757,   368,   105,   163,     4,  2650,  2669,\n",
            "         1125,   128,   688,   427,    55,  2190,   431,    24,    68,  5871,\n",
            "          368]) tensor([ 0, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Smaller Sample"
      ],
      "metadata": {
        "id": "mUCQZ7zVHQ1N"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix seed value\n",
        "SEED = 2345\n",
        "random.seed(SEED)\n",
        "\n",
        "# We will be using 500 observations for text and 100 for valid daatset\n",
        "# We do not need valid for overfitting, it will help to check errors in code\n",
        "train_sample_size = 500\n",
        "valid_sample_size = 100\n",
        "\n",
        "# Getting n random indices\n",
        "train_subset_indices = random.sample(range(0, len(trainset)), train_sample_size)\n",
        "valid_subset_indices = random.sample(range(0, len(validset)), valid_sample_size)\n",
        "\n",
        "# Getting subset of dataset\n",
        "train_subset = torch.utils.data.Subset(trainset, train_subset_indices)\n",
        "valid_subset = torch.utils.data.Subset(validset, valid_subset_indices)"
      ],
      "metadata": {
        "id": "NgXg5to6HWGT"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PIh63mSCuSN"
      },
      "source": [
        "# <font color = 'blue'> **Model for ANN**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPCustom(nn.Module):\n",
        "  def __init__(self, embed_dim, vocab_size, h_sizes_list, d_prob_list, output_dim, non_linearity, batch_norm, task, pretrained_weights):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.output_dim = output_dim\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embed_dim = embed_dim\n",
        "    self.h_sizes_list = h_sizes_list\n",
        "    self.d_prob_list = d_prob_list\n",
        "    self.batch_norm = batch_norm\n",
        "    self.task = task\n",
        "    self.pretrained_weights= pretrained_weights\n",
        "    \n",
        "    self.non_linearity = non_linearity\n",
        "\n",
        "    model_layers = []\n",
        "\n",
        "    # embedding_layer\n",
        "    if self.task == 2:\n",
        "       self.embedding = nn.EmbeddingBag(self.vocab_size, self.embed_dim)\n",
        "\n",
        "    # Task 5\n",
        "    if self.task == 5:\n",
        "       self.embedding = nn.EmbeddingBag(vocab_size, self.embed_dim).from_pretrained(pretrained_weights,\n",
        "                                                                               freeze = True)\n",
        "       \n",
        "    # Task 6\n",
        "    if self.task == 6:\n",
        "       self.embedding = nn.EmbeddingBag(vocab_size, self.embed_dim).from_pretrained(pretrained_weights,\n",
        "                                                                               freeze = False)\n",
        "\n",
        "    input_dim = self.embed_dim\n",
        "    # hidden layers, droput, non_linearity, batchnorm layers\n",
        "    for k, hidden_size in enumerate(self.h_sizes_list):\n",
        "      # hidden_layer\n",
        "      model_layers.append(nn.Linear(input_dim, hidden_size))\n",
        "      # Activation function\n",
        "      model_layers.append(self.non_linearity)\n",
        "      # Dropout Layer\n",
        "      model_layers.append(nn.Dropout(p=self.d_prob_list[k]))\n",
        "      # Batch_Norm Layer\n",
        "      if self.batch_norm:\n",
        "        model_layers.append(nn.BatchNorm1d(hidden_size, momentum = 0.9))\n",
        "      input_dim = hidden_size\n",
        "\n",
        "    # output layer  \n",
        "    if len(self.h_sizes_list)>0:\n",
        "        model_layers.append(nn.Linear(self.h_sizes_list[-1], self.output_dim))\n",
        "    else:\n",
        "        model_layers.append(nn.Linear(self.embed_dim, self.output_dim))\n",
        "\n",
        "    self.module_list = nn.ModuleList(model_layers)\n",
        "    \n",
        "\n",
        "  def forward(self, x, offsets):\n",
        "    out = self.embedding(x, offsets) # batchsize, embedding_dim\n",
        "    for layer in self.module_list:\n",
        "      out = layer(out)\n",
        "    return out\n",
        "\n",
        "    # Note : We do not need to apply softmax as we will be using nn.CrossEntropy Loss"
      ],
      "metadata": {
        "id": "J8GoOj6KZjOX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqI_o6qwy6lb"
      },
      "source": [
        "## <Font color = 'pickle'>**Function for Training  Loops**\n",
        "\n",
        "**Model Training** involves five steps: \n",
        "\n",
        "- Step 0: Randomly initialize parameters / weights\n",
        "- Step 1: Compute model's predictions - forward pass\n",
        "- Step 2: Compute loss\n",
        "- Step 3: Compute the gradients\n",
        "- Step 4: Update the parameters\n",
        "- Step 5: Repeat steps 1 - 4\n",
        "\n",
        "Model training is repeating this process over and over, for many **epochs**.\n",
        "\n",
        "We will specify number of ***epochs*** and during each epoch we will iterate over the complete dataset and will keep on updating the parameters.\n",
        "\n",
        "***Learning rate*** and ***epochs*** are known as hyperparameters. We have to adjust the values of these two based on validation dataset.\n",
        "\n",
        "We will now create functions for step 1 to 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:53:29.864165Z",
          "iopub.status.busy": "2022-10-24T09:53:29.864000Z",
          "iopub.status.idle": "2022-10-24T09:53:29.893835Z",
          "shell.execute_reply": "2022-10-24T09:53:29.893176Z",
          "shell.execute_reply.started": "2022-10-24T09:53:29.864153Z"
        },
        "tags": [],
        "id": "L9fNAtwqbHE6"
      },
      "outputs": [],
      "source": [
        "def train(train_loader, loss_function, model, optimizer, grad_clipping, max_norm, log_batch, log_interval):\n",
        "\n",
        "  # Training Loop \n",
        "\n",
        "  # initilalize variables as global\n",
        "  # these counts will be updated every epoch\n",
        "  global batch_ct_train\n",
        "\n",
        "  # Initialize train_loss at the he start of the epoch\n",
        "  running_train_loss = 0\n",
        "  running_train_correct = 0\n",
        "  \n",
        "  # put the model in training mode\n",
        "\n",
        "  model.train()\n",
        "  # Iterate on batches from the dataset using train_loader\n",
        "  for input_, targets, offsets in train_loader:\n",
        "    \n",
        "    # move inputs and outputs to GPUs\n",
        "    input_ = input_.to(device)\n",
        "    targets = targets.to(device)\n",
        "    offsets = offsets.to(device)\n",
        "\n",
        "\n",
        "    # Step 1: Forward Pass: Compute model's predictions \n",
        "    output = model(input_,offsets)\n",
        "    \n",
        "    # Step 2: Compute loss\n",
        "    loss = loss_function(output, targets.float())\n",
        "\n",
        "    # Correct prediction\n",
        "    # y_pred = torch.argmax(output, dim = 1)\n",
        "    # correct = torch.sum(y_pred == targets)\n",
        "\n",
        "    batch_ct_train += 1\n",
        "\n",
        "    # Step 3: Backward pass -Compute the gradients\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Gradient Clipping\n",
        "    if grad_clipping:\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm, norm_type=2)\n",
        "\n",
        "    # Step 4: Update the parameters\n",
        "    optimizer.step()\n",
        "          \n",
        "    # Add train loss of a batch \n",
        "    running_train_loss += loss.item()\n",
        "\n",
        "    # Add Corect counts of a batch\n",
        "    # running_train_correct += correct\n",
        "\n",
        "    # log batch loss and accuracy\n",
        "    if log_batch:\n",
        "      if ((batch_ct_train + 1) % log_interval) == 0:\n",
        "        wandb.log({f\"Train Batch Loss  :\": loss})\n",
        "        # wandb.log({f\"Train Batch Acc :\": correct/len(targets)})\n",
        "\n",
        "  \n",
        "  # Calculate mean train loss for the whole dataset for a particular epoch\n",
        "  train_loss = running_train_loss/len(train_loader)\n",
        "\n",
        "  # Calculate accuracy for the whole dataset for a particular epoch\n",
        "  # train_acc = running_train_correct/len(train_loader.dataset)\n",
        "  \n",
        "\n",
        "  return train_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeLm-GI5bW2V"
      },
      "source": [
        "## <Font color = 'pickle'>**Function for Validation Loops**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:10:52.543093Z",
          "iopub.status.busy": "2022-10-24T10:10:52.542892Z",
          "iopub.status.idle": "2022-10-24T10:10:52.568808Z",
          "shell.execute_reply": "2022-10-24T10:10:52.568348Z",
          "shell.execute_reply.started": "2022-10-24T10:10:52.543080Z"
        },
        "tags": [],
        "id": "mjBYhfpTbHE6"
      },
      "outputs": [],
      "source": [
        "def validate(valid_loader, loss_function, model, log_batch, log_interval):\n",
        "\n",
        "  # initilalize variables as global\n",
        "  # these counts will be updated every epoch\n",
        "  global batch_ct_valid\n",
        "\n",
        "  # Validation/Test loop\n",
        "  # Initialize valid_loss at the he strat of the epoch\n",
        "  running_val_loss = 0\n",
        "  # running_val_correct = 0\n",
        "\n",
        "  # put the model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for input_, targets, offsets in valid_loader:\n",
        "\n",
        "      # move inputs and outputs to GPUs\n",
        "      input_ = input_.to(device)\n",
        "      targets = targets.to(device)\n",
        "      offsets = offsets.to(device)\n",
        "\n",
        "      # Step 1: Forward Pass: Compute model's predictions \n",
        "      output = model(input_,offsets)\n",
        "\n",
        "      # Step 2: Compute loss\n",
        "      loss = loss_function(output, targets.float())\n",
        "\n",
        "      # Correct Predictions\n",
        "      # y_pred = torch.argmax(output, dim = 1)\n",
        "      # correct = torch.sum(y_pred == targets)\n",
        "\n",
        "      batch_ct_valid += 1\n",
        "\n",
        "      # Add val loss of a batch \n",
        "      running_val_loss += loss.item()\n",
        "\n",
        "      # Add correct count for each batch\n",
        "      # running_val_correct += correct\n",
        "\n",
        "      # log batch loss and accuracy\n",
        "      if log_batch:\n",
        "        if ((batch_ct_valid + 1) % log_interval) == 0:\n",
        "          wandb.log({f\"Valid Batch Loss  :\": loss})\n",
        "          # wandb.log({f\"Valid Batch Accuracy :\": correct/len(targets)})\n",
        "\n",
        "    # Calculate mean val loss for the whole dataset for a particular epoch\n",
        "    val_loss = running_val_loss/len(valid_loader)\n",
        "\n",
        "    # Calculate accuracy for the whole dataset for a particular epoch\n",
        "    # val_acc = running_val_correct/len(valid_loader.dataset)\n",
        "\n",
        "    # scheduler step\n",
        "    scheduler.step(val_loss)\n",
        "    # scheduler.step()\n",
        "    \n",
        "  return val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os41TZylbHE6"
      },
      "source": [
        "## <Font color = 'pickle'>**Function for Model Training**\n",
        "    \n",
        "We will now create a function for step 5 of model training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:10:55.067141Z",
          "iopub.status.busy": "2022-10-24T10:10:55.066963Z",
          "iopub.status.idle": "2022-10-24T10:10:55.098680Z",
          "shell.execute_reply": "2022-10-24T10:10:55.098149Z",
          "shell.execute_reply.started": "2022-10-24T10:10:55.067127Z"
        },
        "tags": [],
        "id": "mlrbWAM7bHE6"
      },
      "outputs": [],
      "source": [
        "def train_loop(train_loader, valid_loader, model, optimizer, loss_function, epochs, device, patience, early_stopping,\n",
        "               file_model, save_best_model):\n",
        "    \n",
        "  \"\"\" \n",
        "  Function for training the model and plotting the graph for train & validation loss vs epoch.\n",
        "  Input: iterator for train dataset, initial weights and bias, epochs, learning rate, batch size.\n",
        "  Output: final weights, bias and train loss and validation loss for each epoch.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create lists to store train and val loss at each epoch\n",
        "  train_loss_history = []\n",
        "  valid_loss_history = []\n",
        "  # train_acc_history = []\n",
        "  # valid_acc_history = []\n",
        "\n",
        "  # initialize variables for early stopping\n",
        "\n",
        "  delta = 0\n",
        "  best_score = None\n",
        "  valid_loss_min = np.Inf\n",
        "  counter_early_stop=0\n",
        "  early_stop=False\n",
        "\n",
        "  # Iterate for the given number of epochs\n",
        "  # Step 5: Repeat steps 1 - 4\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    t0 = datetime.now()\n",
        "\n",
        "    # Get train loss for one epoch\n",
        "    train_loss  = train(train_loader, loss_function, model, optimizer, \n",
        "                                  wandb.config.GRAD_CLIPPING, wandb.config.MAX_NORM,\n",
        "                                  wandb.config.LOG_BATCH, wandb.config.LOG_INTERVAL)\n",
        "    valid_loss   = validate(valid_loader, loss_function, model, \n",
        "                                       wandb.config.LOG_BATCH, wandb.config.LOG_INTERVAL)\n",
        "\n",
        "    dt = datetime.now() - t0\n",
        "\n",
        "    # Save history of the Losses and accuracy\n",
        "    train_loss_history.append(train_loss)\n",
        "    # train_acc_history.append(train_acc)\n",
        "\n",
        "    valid_loss_history.append(valid_loss)\n",
        "    # valid_acc_history.append(valid_acc)\n",
        "\n",
        "    # Log the train and valid loss to wandb\n",
        "    wandb.log({f\"Train Loss :\": train_loss, \"epoch\": epoch})\n",
        "    # wandb.log({f\"Train Acc :\": train_acc, \"epoch\": epoch})\n",
        "\n",
        "    wandb.log({f\"Valid Loss :\": valid_loss, \"epoch\": epoch})\n",
        "    # wandb.log({f\"Valid Acc :\": valid_acc, \"epoch\": epoch})\n",
        "\n",
        "    if early_stopping:\n",
        "      score = -valid_loss\n",
        "      if best_score is None:\n",
        "        best_score=score\n",
        "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model...')\n",
        "        torch.save(model.state_dict(), file_model)\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "      elif score < best_score + delta:\n",
        "        counter_early_stop += 1\n",
        "        print(f'Early stoping counter: {counter_early_stop} out of {patience}')\n",
        "        if counter_early_stop > patience:\n",
        "          early_stop = True\n",
        "\n",
        "\n",
        "      else:\n",
        "        best_score = score\n",
        "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')\n",
        "        torch.save(model.state_dict(), file_model)\n",
        "        counter_early_stop=0\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "      if early_stop:\n",
        "        print('Early Stopping')\n",
        "        break\n",
        "\n",
        "    elif save_best_model:\n",
        "\n",
        "      score = -valid_loss\n",
        "      if best_score is None:\n",
        "        best_score=score\n",
        "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model...')\n",
        "        torch.save(model.state_dict(), file_model)\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "      elif score < best_score + delta:\n",
        "        print(f'Validation loss has not decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Not Saving Model...')\n",
        "      \n",
        "      else:\n",
        "        best_score = score\n",
        "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')\n",
        "        torch.save(model.state_dict(), file_model)\n",
        "        valid_loss_min = valid_loss\n",
        "        \n",
        "    else:\n",
        "        torch.save(model.state_dict(), file_model)\n",
        "    \n",
        "    # Print the train loss and accuracy for given number of epochs, batch size and number of samples\n",
        "    print(f'Epoch : {epoch+1} / {epochs}')\n",
        "    print(f'Time to complete {epoch+1} is {dt}')\n",
        "    print(f'Learning rate: {scheduler._last_lr[0]}')\n",
        "    print(f'Train Loss: {train_loss : .4f} ')\n",
        "    print(f'Valid Loss: {valid_loss : .4f} ')\n",
        "    print()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  return train_loss_history, valid_loss_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ET6YsTebHE6"
      },
      "source": [
        "## <Font color = 'pickle'>**Function for Accuracy and Predictions**\n",
        "\n",
        "Now we have final values for weights and bias after training the model. We will use these values to make predictions on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:10:55.389964Z",
          "iopub.status.busy": "2022-10-24T10:10:55.389758Z",
          "iopub.status.idle": "2022-10-24T10:10:55.418810Z",
          "shell.execute_reply": "2022-10-24T10:10:55.418102Z",
          "shell.execute_reply.started": "2022-10-24T10:10:55.389950Z"
        },
        "tags": [],
        "id": "dV3Mbr3TbHE7"
      },
      "outputs": [],
      "source": [
        "def get_pred(data_loader, model):\n",
        "  \"\"\" \n",
        "  Function to get predictions for a given test set and calculate accuracy.\n",
        "  Input: Iterator to the test set.\n",
        "  Output: Prections and Accuracy for test set.\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    # Array to store predicted labels\n",
        "    predictions = torch.Tensor()\n",
        "    predictions = predictions.to(device)\n",
        "    \n",
        "    outputs = torch.Tensor()\n",
        "    outputs = outputs.to(device)\n",
        "\n",
        "    # Array to store actual labels\n",
        "    y = torch.Tensor()\n",
        "    y = y.to(device)\n",
        "    # Iterate over batches from test set\n",
        "    for input_, targets, offsets in data_loader:\n",
        "      \n",
        "      # move inputs and outputs to GPUs\n",
        "      input_ = input_.to(device)\n",
        "      targets = targets.to(device)\n",
        "      offsets = offsets.to(device)\n",
        "\n",
        "      # Calculated the predicted labels\n",
        "      output = model(input_,offsets)\n",
        "      predicted_y = output.clone()\n",
        "  \n",
        "      # Update teh output \n",
        "      predicted_y[predicted_y>0] = 1\n",
        "      predicted_y[predicted_y<=0] =0\n",
        "\n",
        "      # Add the predicted labels to the array\n",
        "      predictions = torch.cat((predictions, predicted_y)) \n",
        "    \n",
        "      outputs = torch.cat((outputs, output)) \n",
        "\n",
        "      # Add the actual labels to the array\n",
        "      y = torch.cat((y, targets)) \n",
        "\n",
        "  # Return array containing predictions and accuracy\n",
        "  return y, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nF5iTy_VqdV"
      },
      "source": [
        "# <Font color = 'pickle'>**Meta Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:10:55.752082Z",
          "iopub.status.busy": "2022-10-24T10:10:55.751573Z",
          "iopub.status.idle": "2022-10-24T10:10:55.777422Z",
          "shell.execute_reply": "2022-10-24T10:10:55.776854Z",
          "shell.execute_reply.started": "2022-10-24T10:10:55.752066Z"
        },
        "id": "TAuG3mxBWHaz",
        "tags": []
      },
      "outputs": [],
      "source": [
        "hyperparameters = SimpleNamespace(\n",
        "    EMBED_DIM = 5000,\n",
        "    VOCAB_SIZE = len(multilabel_vocab),\n",
        "    OUTPUT_DIM = 10,\n",
        "    HIDDEN_SIZES_LIST = [500,200], # 100 layers of size 200  [200]*100\n",
        "    DPROB_LIST = [0,0],\n",
        "    NON_LINEARITY= nn.SELU(),\n",
        "    PRETRAINED_WEIGHTS_TENSOR = 0,#torch.tensor(pretrained_weights).float(),\n",
        "    BATCH_NORM = True,\n",
        "    EPOCHS = 10,\n",
        "    TASK = 2,    \n",
        "    BATCH_SIZE = 256,\n",
        "    LEARNING_RATE = 0.02,\n",
        "    DATASET=\"MultiLabel\",\n",
        "    ARCHITECTUREe=\"2_hidden_layers\",\n",
        "    LOG_INTERVAL = 25,\n",
        "    LOG_BATCH = True,\n",
        "    FILE_MODEL = save_model_folder/'hw6_part_B_full.pt',\n",
        "    GRAD_CLIPPING = False,\n",
        "    MAX_NORM = 0,\n",
        "    MOMENTUM = 0,\n",
        "    PATIENCE = 10,\n",
        "    EARLY_STOPPING = True,\n",
        "    SCHEDULER_FACTOR = 0.5,\n",
        "    SCHEDULER_PATIENCE = 0,\n",
        "    WEIGHT_DECAY = 0.0005,\n",
        "    SAVE_BEST_MODEL = True,\n",
        "    DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available() "
      ],
      "metadata": {
        "id": "QKSmI124WrGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3549e04d-27cd-42d0-88a3-422c1da2afcc"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVk_RctgdPRP"
      },
      "source": [
        "# <Font color = 'pickle'>**Data Loaders, Loss Function, Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259,
          "referenced_widgets": [
            "c58a79bec31149a2a450668b65c7b6a6",
            "556af826137f43f2ace4ce2e2375f634",
            "bb9a8cce0fc6448b91ec8eb63330ddd3",
            "3a4953de045c46eb9ebf5f963b88cbcd",
            "d243366b5d55441589e0d4b7b8e13383",
            "23d5f8b7ceb54495913ddfbd8a4487ab",
            "345432f73833446984a9fc9129b87cc8",
            "ef0bec2ba12a4594b3e4e379cb7c3280"
          ]
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:10:56.268730Z",
          "iopub.status.busy": "2022-10-24T10:10:56.268433Z",
          "iopub.status.idle": "2022-10-24T10:11:01.517607Z",
          "shell.execute_reply": "2022-10-24T10:11:01.517178Z",
          "shell.execute_reply.started": "2022-10-24T10:10:56.268709Z"
        },
        "id": "3kCRNDlu-zbE",
        "outputId": "1e14b794-f55f-46f9-a609-bebe024e02a4",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:pgz51dpr) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c58a79bec31149a2a450668b65c7b6a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">task2</strong>: <a href=\"https://wandb.ai/teffygeorge/NLP_HW6_part2/runs/pgz51dpr\" target=\"_blank\">https://wandb.ai/teffygeorge/NLP_HW6_part2/runs/pgz51dpr</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221127_040457-pgz51dpr/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:pgz51dpr). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221127_040515-2fkkkj9u</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/teffygeorge/NLP_HW6_part2/runs/2fkkkj9u\" target=\"_blank\">task2</a></strong> to <a href=\"https://wandb.ai/teffygeorge/NLP_HW6_part2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/teffygeorge/NLP_HW6_part2/runs/2fkkkj9u?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fd39ec048d0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Initialize a new project\n",
        "import random\n",
        "wandb.init(name = 'task2', project = 'NLP_HW6_part2', config = hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.518431Z",
          "iopub.status.busy": "2022-10-24T10:11:01.518292Z",
          "iopub.status.idle": "2022-10-24T10:11:01.543960Z",
          "shell.execute_reply": "2022-10-24T10:11:01.543555Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.518418Z"
        },
        "id": "Gnl8vsAN-5Tq",
        "outputId": "dcf0aac7-472b-47d4-fc56-6c00c48227af",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "namespace(ARCHITECTUREe='2_hidden_layers', BATCH_NORM=True, BATCH_SIZE=256, DATASET='MultiLabel', DEVICE=device(type='cuda', index=0), DPROB_LIST=[0, 0], EARLY_STOPPING=True, EMBED_DIM=5000, EPOCHS=10, FILE_MODEL=PosixPath('/content/drive/MyDrive/NLP/Homework6/models/hw6_part_B_full.pt'), GRAD_CLIPPING=False, HIDDEN_SIZES_LIST=[500, 200], LEARNING_RATE=0.02, LOG_BATCH=True, LOG_INTERVAL=25, MAX_NORM=0, MOMENTUM=0, NON_LINEARITY=SELU(), OUTPUT_DIM=10, PATIENCE=10, PRETRAINED_WEIGHTS_TENSOR=0, SAVE_BEST_MODEL=True, SCHEDULER_FACTOR=0.5, SCHEDULER_PATIENCE=0, TASK=2, VOCAB_SIZE=90235, WEIGHT_DECAY=0.0005)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "wandb.config = hyperparameters\n",
        "wandb.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.544753Z",
          "iopub.status.busy": "2022-10-24T10:11:01.544508Z",
          "iopub.status.idle": "2022-10-24T10:11:01.655272Z",
          "shell.execute_reply": "2022-10-24T10:11:01.654814Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.544740Z"
        },
        "id": "fZ6ZoM9WaS_M",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Fix seed value\n",
        "SEED = 2345\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Data Loader\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=wandb.config.BATCH_SIZE, shuffle = True, \n",
        "                                           collate_fn=collate_batch, num_workers = 4)\n",
        "valid_loader = torch.utils.data.DataLoader(validset, batch_size=wandb.config.BATCH_SIZE, shuffle = False, \n",
        "                                           collate_fn=collate_batch,  num_workers = 4)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=wandb.config.BATCH_SIZE,   shuffle = False, \n",
        "                                          collate_fn=collate_batch,  num_workers = 4)\n",
        "\n",
        "# cross entropy loss function\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# model \n",
        "model_multilabel = MLPCustom(wandb.config.EMBED_DIM, \n",
        "                       wandb.config.VOCAB_SIZE, \n",
        "                       wandb.config.HIDDEN_SIZES_LIST, \n",
        "                       wandb.config.DPROB_LIST,\n",
        "                       wandb.config.OUTPUT_DIM, \n",
        "                       wandb.config.NON_LINEARITY,\n",
        "                       wandb.config.BATCH_NORM,\n",
        "                       wandb.config.TASK,\n",
        "                       wandb.config.PRETRAINED_WEIGHTS_TENSOR)\n",
        "\n",
        "model_multilabel.to(wandb.config.DEVICE)\n",
        "\n",
        "def init_weights(m):\n",
        "  if type(m) == nn.Linear:\n",
        "      torch.nn.init.kaiming_normal_(m.weight)\n",
        "      torch.nn.init.zeros_(m.bias)\n",
        "        \n",
        "# apply initialization recursively  to all modules\n",
        "# model_multilabel.apply(init_weights)\n",
        "\n",
        "# Intialize stochiastic gradient descent optimizer\n",
        "optimizer = torch.optim.Adam(model_multilabel.parameters(), \n",
        "                             lr = wandb.config.LEARNING_RATE, \n",
        "                             weight_decay=wandb.config.WEIGHT_DECAY)\n",
        "\n",
        "# wandb.config.OPTIMIZER = optimizer\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor= wandb.config.SCHEDULER_FACTOR, \n",
        "                              patience=wandb.config.SCHEDULER_PATIENCE, verbose=True)\n",
        "\n",
        "#scheduler = StepLR(optimizer, gamma=0.4,step_size=1, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.config.DEVICE"
      ],
      "metadata": {
        "id": "02lUNqRJYGxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6948b705-c703-49d9-95c0-3159ef1a26f8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.656283Z",
          "iopub.status.busy": "2022-10-24T10:11:01.656152Z",
          "iopub.status.idle": "2022-10-24T10:11:01.683125Z",
          "shell.execute_reply": "2022-10-24T10:11:01.682778Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.656271Z"
        },
        "id": "6etbfbQkm-zv",
        "outputId": "d1d1bf9d-9255-4e4d-9937-09ef04a1582b",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "namespace(ARCHITECTUREe='2_hidden_layers', BATCH_NORM=True, BATCH_SIZE=256, DATASET='MultiLabel', DEVICE=device(type='cuda', index=0), DPROB_LIST=[0, 0], EARLY_STOPPING=True, EMBED_DIM=5000, EPOCHS=10, FILE_MODEL=PosixPath('/content/drive/MyDrive/NLP/Homework6/models/hw6_part_B_full.pt'), GRAD_CLIPPING=False, HIDDEN_SIZES_LIST=[500, 200], LEARNING_RATE=0.02, LOG_BATCH=True, LOG_INTERVAL=25, MAX_NORM=0, MOMENTUM=0, NON_LINEARITY=SELU(), OUTPUT_DIM=10, PATIENCE=10, PRETRAINED_WEIGHTS_TENSOR=0, SAVE_BEST_MODEL=True, SCHEDULER_FACTOR=0.5, SCHEDULER_PATIENCE=0, TASK=2, VOCAB_SIZE=90235, WEIGHT_DECAY=0.0005)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "wandb.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffeGh2dcukdK"
      },
      "source": [
        "# <Font color = 'pickle'>**Sanity Check**\n",
        "- Check the loss without any training. For Cross entropy the expected value will be log(number of classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.683806Z",
          "iopub.status.busy": "2022-10-24T10:11:01.683633Z",
          "iopub.status.idle": "2022-10-24T10:11:01.920580Z",
          "shell.execute_reply": "2022-10-24T10:11:01.920065Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.683793Z"
        },
        "id": "p2Gx7jgbumux",
        "tags": []
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9hqWoJoVr2_",
        "outputId": "a6cf5be8-8be0-4865-a377-24e2a66aebc2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_, targets, offsets in train_loader:\n",
        "  \n",
        "  # move inputs and outputs to GPUs\n",
        "  input_ = input_.to(device)\n",
        "  targets = targets.to(device)\n",
        "  offsets = offsets.to(device)\n",
        "  model_multilabel.eval()\n",
        "  # Forward pass\n",
        "  output = model_multilabel(input_, offsets)\n",
        "  loss = loss_function(output, targets.float())\n",
        "  print(f'Actual loss: {loss}')\n",
        "  break\n",
        "\n",
        "print(f'Expected Theoretical loss: {np.log(2)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcGf8uhyU73Y",
        "outputId": "806acb1a-06ee-48db-adc0-6bdfb6f1b0fb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual loss: 0.6931886672973633\n",
            "Expected Theoretical loss: 0.6931471805599453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0_zWk0Ib74K"
      },
      "source": [
        "# <Font color = 'pickle'>**Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.921385Z",
          "iopub.status.busy": "2022-10-24T10:11:01.921236Z",
          "iopub.status.idle": "2022-10-24T10:11:01.957938Z",
          "shell.execute_reply": "2022-10-24T10:11:01.957574Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.921369Z"
        },
        "id": "KczRQvKwiH_y",
        "outputId": "8c6d905e-0c84-4c4b-cd63-cd3da6ebd7c9",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<wandb.wandb_torch.TorchGraph at 0x7fd39ebce290>]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "wandb.watch(model_multilabel, log = 'all', log_freq=25, log_graph=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "f8cAAwDOOtjy"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.958733Z",
          "iopub.status.busy": "2022-10-24T10:11:01.958548Z",
          "iopub.status.idle": "2022-10-24T10:12:09.085757Z",
          "shell.execute_reply": "2022-10-24T10:12:09.085279Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.958718Z"
        },
        "id": "LckLb_9bhZDw",
        "tags": [],
        "outputId": "3911b198-adf3-4295-e2cc-4ed85205230f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (inf --> 0.308549). Saving Model...\n",
            "Epoch : 1 / 10\n",
            "Time to complete 1 is 0:01:21.026077\n",
            "Learning rate: 0.02\n",
            "Train Loss:  0.2139 \n",
            "Valid Loss:  0.3085 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.308549 --> 0.178167). Saving model...\n",
            "Epoch : 2 / 10\n",
            "Time to complete 2 is 0:01:25.301858\n",
            "Learning rate: 0.02\n",
            "Train Loss:  0.1709 \n",
            "Valid Loss:  0.1782 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.178167 --> 0.175621). Saving model...\n",
            "Epoch : 3 / 10\n",
            "Time to complete 3 is 0:01:23.963741\n",
            "Learning rate: 0.02\n",
            "Train Loss:  0.1617 \n",
            "Valid Loss:  0.1756 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.175621 --> 0.153460). Saving model...\n",
            "Epoch : 4 / 10\n",
            "Time to complete 4 is 0:01:25.236507\n",
            "Learning rate: 0.02\n",
            "Train Loss:  0.1475 \n",
            "Valid Loss:  0.1535 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00005: reducing learning rate of group 0 to 1.0000e-02.\n",
            "Early stoping counter: 1 out of 10\n",
            "Epoch : 5 / 10\n",
            "Time to complete 5 is 0:01:26.931339\n",
            "Learning rate: 0.01\n",
            "Train Loss:  0.1392 \n",
            "Valid Loss:  0.1562 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.153460 --> 0.133675). Saving model...\n",
            "Epoch : 6 / 10\n",
            "Time to complete 6 is 0:01:22.641608\n",
            "Learning rate: 0.01\n",
            "Train Loss:  0.1236 \n",
            "Valid Loss:  0.1337 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00007: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Early stoping counter: 1 out of 10\n",
            "Epoch : 7 / 10\n",
            "Time to complete 7 is 0:01:24.845663\n",
            "Learning rate: 0.005\n",
            "Train Loss:  0.1229 \n",
            "Valid Loss:  0.1378 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.133675 --> 0.125764). Saving model...\n",
            "Epoch : 8 / 10\n",
            "Time to complete 8 is 0:01:21.814651\n",
            "Learning rate: 0.005\n",
            "Train Loss:  0.1071 \n",
            "Valid Loss:  0.1258 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00009: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Early stoping counter: 1 out of 10\n",
            "Epoch : 9 / 10\n",
            "Time to complete 9 is 0:01:26.815689\n",
            "Learning rate: 0.0025\n",
            "Train Loss:  0.1048 \n",
            "Valid Loss:  0.1366 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.125764 --> 0.119679). Saving model...\n",
            "Epoch : 10 / 10\n",
            "Time to complete 10 is 0:01:21.955316\n",
            "Learning rate: 0.0025\n",
            "Train Loss:  0.0927 \n",
            "Valid Loss:  0.1197 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# See live graphs in the notebook.\n",
        "#%%wandb \n",
        "# See live graphs in the notebook.\n",
        "#%%wandb \n",
        "batch_ct_train, batch_ct_valid = 0, 0\n",
        "train_loss_history, valid_loss_history = train_loop(train_loader, \n",
        "                                                     valid_loader, \n",
        "                                                                                          model_multilabel, \n",
        "                                                                                          optimizer,\n",
        "                                                                                          loss_function, \n",
        "                                                                                          wandb.config.EPOCHS, \n",
        "                                                                                          wandb.config.DEVICE,\n",
        "                                                                                          wandb.config.PATIENCE, \n",
        "                                                                                          wandb.config.EARLY_STOPPING,\n",
        "                                                                                          wandb.config.FILE_MODEL,\n",
        "                                                                                          wandb.config.SAVE_BEST_MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-Cj1f2Qb74K"
      },
      "source": [
        "# <Font color = 'pickle'>**Get Accuracy, Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:12:09.086719Z",
          "iopub.status.busy": "2022-10-24T10:12:09.086506Z",
          "iopub.status.idle": "2022-10-24T10:12:09.119252Z",
          "shell.execute_reply": "2022-10-24T10:12:09.118859Z",
          "shell.execute_reply.started": "2022-10-24T10:12:09.086701Z"
        },
        "id": "dZQF1CbgKEKd",
        "outputId": "a8e1febb-59de-46bd-94a4-620e55c4655f",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:12:09.120013Z",
          "iopub.status.busy": "2022-10-24T10:12:09.119827Z",
          "iopub.status.idle": "2022-10-24T10:12:09.259339Z",
          "shell.execute_reply": "2022-10-24T10:12:09.258892Z",
          "shell.execute_reply.started": "2022-10-24T10:12:09.119999Z"
        },
        "id": "yw7GhoZuRdIO",
        "outputId": "7d4ac7e4-a72d-4bdf-a0bf-9b5cd27f77ff",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "model_nn = MLPCustom(wandb.config.EMBED_DIM, \n",
        "                       wandb.config.VOCAB_SIZE, \n",
        "                       wandb.config.HIDDEN_SIZES_LIST, \n",
        "                       wandb.config.DPROB_LIST,\n",
        "                       wandb.config.OUTPUT_DIM, \n",
        "                       wandb.config.NON_LINEARITY,\n",
        "                       wandb.config.BATCH_NORM,\n",
        "                       wandb.config.TASK,\n",
        "                       wandb.config.PRETRAINED_WEIGHTS_TENSOR)\n",
        "model_nn.to(wandb.config.DEVICE)\n",
        "model_nn.load_state_dict(torch.load(wandb.config.FILE_MODEL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:12:09.260788Z",
          "iopub.status.busy": "2022-10-24T10:12:09.260622Z",
          "iopub.status.idle": "2022-10-24T10:12:10.954206Z",
          "shell.execute_reply": "2022-10-24T10:12:10.953655Z",
          "shell.execute_reply.started": "2022-10-24T10:12:09.260776Z"
        },
        "tags": [],
        "id": "NoVxQEcibHE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d5cd3b-3db9-445e-f9f8-4c3929fe502b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ],
      "source": [
        "# Get the prediction and labels\n",
        "y_train,  y_predicted_train = get_pred(train_loader, model_nn)\n",
        "y_valid, y_predicted_valid = get_pred(valid_loader, model_nn)\n",
        "y_test,  y_predicted_test  = get_pred(test_loader, model_nn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PCfbKafGC_R",
        "outputId": "ad782765-2819-4ac2-a490-051f020b9718"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 15.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:12:10.954984Z",
          "iopub.status.busy": "2022-10-24T10:12:10.954792Z",
          "iopub.status.idle": "2022-10-24T10:12:10.989733Z",
          "shell.execute_reply": "2022-10-24T10:12:10.989257Z",
          "shell.execute_reply.started": "2022-10-24T10:12:10.954948Z"
        },
        "id": "vcfIlMd3FKAX",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torchmetrics import F1Score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1score  = F1Score(num_classes=10, mdmc_average= 'global').to(device)"
      ],
      "metadata": {
        "id": "5AtiOdRcOQf-"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_f1_score = f1score( y_predicted_train, y_train.long())"
      ],
      "metadata": {
        "id": "uLK3AdYgOSUj"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_f1_score"
      ],
      "metadata": {
        "id": "au5qDxKxOVVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b851164-365a-4273-d2f1-d7b8aab2228f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9268, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert these to numpy array\n",
        "y_train, y_predicted_train  = y_train.cpu().numpy(), y_predicted_train.cpu().numpy() \n",
        "y_valid, y_predicted_valid  = y_valid.cpu().numpy(), y_predicted_valid.cpu().numpy() \n",
        "y_test, y_predicted_test  = y_test.cpu().numpy(), y_predicted_test.cpu().numpy() "
      ],
      "metadata": {
        "id": "1v3xhcxZOXFB"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "0dcHjEMPOZAA"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_train = f1_score(y_train, y_predicted_train, average = 'micro')\n",
        "f1_score_valid = f1_score(y_valid, y_predicted_valid, average = 'micro')\n",
        "f1_score_test = f1_score(y_test, y_predicted_test, average = 'micro')"
      ],
      "metadata": {
        "id": "ZCpvTbVhOatt"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Accuracy based on saved Model\n",
        "print('f1_score_train', f1_score_train)\n",
        "print('f1_score_valid', f1_score_valid)\n",
        "print('f1_score_test', f1_score_test)"
      ],
      "metadata": {
        "id": "wc-ORijXOcxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8997cfa1-16fc-4584-d7ce-83d5f9589c59"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score_train 0.9267560994212012\n",
            "f1_score_valid 0.8986018454617489\n",
            "f1_score_test 0.8956792327704942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.log({'Train f1 score': f1_score_train})\n",
        "wandb.log({'Valid f1 score': f1_score_valid}) \n",
        "wandb.log({'Test f1 score': f1_score_test})"
      ],
      "metadata": {
        "id": "Lk95ox7vOelP"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "6jkTO6eqOiBi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609,
          "referenced_widgets": [
            "621aab630d574925943bd5fc50480e60",
            "9a8c789140d5456886071fab75b2aca6",
            "efe70104a7ae4acfb9ec58c2dcf04fe7",
            "543bba70ecf84e26acf25bb4aeb3ef31",
            "1e7e3fcbd69b4cc8bf1d76f4bb8f3b88",
            "257e853d3639423db749699c1f696241",
            "03048ef4a2384bd4b602ef294cfecc56",
            "88f8c08d2e11459a8eda6be724e12e06"
          ]
        },
        "outputId": "d5710916-a7cf-4034-e2e2-58fd541af33a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "621aab630d574925943bd5fc50480e60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test f1 score</td><td>▁</td></tr><tr><td>Train Batch Loss  :</td><td>█▅▅▅▅▄▅▅▇▄▄▄▄▃▄▄▄▄▃▄▃▃▂▃▃▂▂▂▃▂▁▂▂▂▃▁▂▁▂▁</td></tr><tr><td>Train Loss :</td><td>█▆▅▄▄▃▃▂▂▁</td></tr><tr><td>Train f1 score</td><td>▁</td></tr><tr><td>Valid Batch Loss  :</td><td>█▄▃▃▃▂▂▃▂▂▂▁▂▂▁</td></tr><tr><td>Valid Loss :</td><td>█▃▃▂▂▂▂▁▂▁</td></tr><tr><td>Valid f1 score</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test f1 score</td><td>0.89568</td></tr><tr><td>Train Batch Loss  :</td><td>0.092</td></tr><tr><td>Train Loss :</td><td>0.09273</td></tr><tr><td>Train f1 score</td><td>0.92676</td></tr><tr><td>Valid Batch Loss  :</td><td>0.11005</td></tr><tr><td>Valid Loss :</td><td>0.11968</td></tr><tr><td>Valid f1 score</td><td>0.8986</td></tr><tr><td>epoch</td><td>9</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">task2</strong>: <a href=\"https://wandb.ai/teffygeorge/NLP_HW6_part2/runs/2fkkkj9u\" target=\"_blank\">https://wandb.ai/teffygeorge/NLP_HW6_part2/runs/2fkkkj9u</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221127_040515-2fkkkj9u/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsNoiByVMGyD"
      },
      "source": [
        "# <Font color = 'pickle'>**TASK 4** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3ktdL-fnwIm"
      },
      "source": [
        "## <font color = 'blue'> Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "import seaborn as sns\n",
        "\n",
        "import custom_preprocessor as cp\n",
        "from  plot_learning_curve import plot_learning_curve as plc\n",
        "\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "import sys\n",
        "import joblib"
      ],
      "metadata": {
        "id": "z5XDIV2tnmSx"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSSacOVpNGa5"
      },
      "source": [
        "## <font color = 'blue'> Gensim vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "class GensimVectorizer(BaseEstimator,TransformerMixin):\n",
        "  np.random.seed(0)\n",
        "  def __init__(self,pretrained_vectors,unk_norm_init=False):\n",
        "    # load in pre-trained word vectors\n",
        "    self.pretrained_vectors= pretrained_vectors\n",
        "    self.vec_size= self.pretrained_vectors.vector_size\n",
        "    self.unk_norm_init = unk_norm_init\n",
        "    self.pretrained_vectors_subset = {}\n",
        "    self.words_not_in_pretrained = []\n",
        "    self.count_missing = 0\n",
        "    self.percent_missing = 0\n",
        "\n",
        "\n",
        "  def fit(self, X,y=None):\n",
        "    '''\n",
        "    Gets the subset of pretrained vectors which are present in vocab\n",
        "    X :  training sentences\n",
        "    '''\n",
        "    counter = Counter()\n",
        "\n",
        "    for sent in X:\n",
        "        counter.update(sent.split())\n",
        "    for token in counter:\n",
        "        try:\n",
        "            self.pretrained_vectors_subset[token] = self.pretrained_vectors.get_vector(token, norm=True)\n",
        "        except:\n",
        "            self.words_not_in_pretrained.append(token)\n",
        "    \n",
        "    ### save so that you can access this after you fit the vectorizer\n",
        "    self.count_missing = len(self.words_not_in_pretrained )\n",
        "    self.percent_missing = self.count_missing / len(counter)\n",
        "    return self\n",
        "    \n",
        "  def transform(self,X,y=None):\n",
        "    X_vector = np.zeros((len(X), self.vec_size))\n",
        "    \n",
        "    for i, sent in enumerate(X):\n",
        "        sent_vector = np.zeros(self.vec_size)\n",
        "        n=0\n",
        "        tokens = sent.split()\n",
        "        for word in tokens:\n",
        "            if word in self.pretrained_vectors_subset.keys():\n",
        "                word_vector=self.pretrained_vectors_subset[word]\n",
        "                sent_vector+= word_vector\n",
        "                n+= 1\n",
        "            else:\n",
        "                if self.unk_norm_init :\n",
        "                    word_vector = np.random.normal(size=  self.vec_size)\n",
        "                    sent_vector+= word_vector\n",
        "                    n+= 1\n",
        "        if n>0:\n",
        "            X_vector[i] = sent_vector/n\n",
        "    return X_vector"
      ],
      "metadata": {
        "id": "OikhYHWZn0FE"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi-VJiGeNZ_T"
      },
      "source": [
        "# <font color = 'blue'>  Classification Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_vectors = KeyedVectors.load('/content/drive/MyDrive/NLP/Homework6/models/model_cbow.bin')"
      ],
      "metadata": {
        "id": "jStmu5eUn9cG"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WK9xCber2_n",
        "outputId": "14d3dee7-b21a-40b9-b215-2feb606b8402"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OneVsRest strategy can be used for multi-label learning,\n",
        "# where a classifier is used to predict multiple labels for instance.\n",
        "# Naive Bayes supports multi-class, but we are in a multi-label scenario,\n",
        "# therefore, we can wrap Naive Bayes in the OneVsRestClassifier\n",
        "# Ref: https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5"
      ],
      "metadata": {
        "id": "YjK0Vk4DrEJb"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will wrap Logistic Regression in OneVsRestClassifier\n",
        "# (since we decompose it into multiple independent binary classification problems)\n",
        "# Reference: https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff"
      ],
      "metadata": {
        "id": "5NaixxChsyGI"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['0','1','2','3','4','5','6','7','8','9']"
      ],
      "metadata": {
        "id": "cR53mjRGtOw7"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "# Using pipeline for applying logistic regression and one vs rest classifier\n",
        "pipeline = Pipeline([\n",
        "                ('vectorizer',GensimVectorizer(pretrained_vectors)),\n",
        "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
        "            ])\n",
        "for category in categories:\n",
        "    print('**Processing {} comments...**'.format(category))\n",
        "    \n",
        "    # Training logistic regression model on train data\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    \n",
        "    # calculating test accuracy\n",
        "    prediction = pipeline.predict(X_test)\n",
        "    print('Test accuracy is {}'.format(accuracy_score(y_test, prediction)))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhKQN_PesYVU",
        "outputId": "5bce8055-dd81-47f8-9c35-bccb4668d07b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Processing 0 comments...**\n",
            "Test accuracy is 0.3777145266708834\n",
            "\n",
            "\n",
            "**Processing 1 comments...**\n",
            "Test accuracy is 0.3776091081593928\n",
            "\n",
            "\n",
            "**Processing 2 comments...**\n",
            "Test accuracy is 0.37781994518237405\n",
            "\n",
            "\n",
            "**Processing 3 comments...**\n",
            "Test accuracy is 0.3777145266708834\n",
            "\n",
            "\n",
            "**Processing 4 comments...**\n",
            "Test accuracy is 0.3777145266708834\n",
            "\n",
            "\n",
            "**Processing 5 comments...**\n",
            "Test accuracy is 0.3777145266708834\n",
            "\n",
            "\n",
            "**Processing 6 comments...**\n",
            "Test accuracy is 0.3777145266708834\n",
            "\n",
            "\n",
            "**Processing 7 comments...**\n",
            "Test accuracy is 0.3777145266708834\n",
            "\n",
            "\n",
            "**Processing 8 comments...**\n",
            "Test accuracy is 0.3777145266708834\n",
            "\n",
            "\n",
            "**Processing 9 comments...**\n",
            "Test accuracy is 0.3777145266708834\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use BinaryRelevance\n",
        "# An ensemble of single-label binary classifiers is trained, one for each class. \n",
        "# Each classifier predicts either the membership or the non-membership of one class.\n",
        "# The union of all classes that were predicted is taken as the multi-label output\n",
        "# Reference: https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff"
      ],
      "metadata": {
        "id": "WH-wYrLfuMX5"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install scikit-multilearn\n",
        "import skmultilearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuXzRkxpup76",
        "outputId": "faacd715-7edd-43e3-9e9d-cfe16d1d168f"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RYGlhbUvuIq",
        "outputId": "632de3b5-16eb-4ea6-95fb-77ab2a2527b6"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using binary relevance\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "# Using pipeline for applying logistic regression and one vs rest classifier\n",
        "pipeline = Pipeline([\n",
        "                ('vectorizer',GensimVectorizer(pretrained_vectors)),\n",
        "                ('clf',  BinaryRelevance(GaussianNB()))\n",
        "            ])\n",
        "for category in categories:\n",
        "    print('**Processing {} comments...**'.format(category))\n",
        "    \n",
        "    # Training logistic regression model on train data\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    \n",
        "    # calculating test accuracy\n",
        "    prediction = pipeline.predict(X_test)\n",
        "    print('Test accuracy is {}'.format(accuracy_score(y_test, prediction)))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH9LQrXWucQn",
        "outputId": "1036732b-f56d-42c6-a451-1ff14a50fba6"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Processing 0 comments...**\n",
            "Test accuracy is 0.2787265443811933\n",
            "\n",
            "\n",
            "**Processing 1 comments...**\n",
            "Test accuracy is 0.2787265443811933\n",
            "\n",
            "\n",
            "**Processing 2 comments...**\n",
            "Test accuracy is 0.2787265443811933\n",
            "\n",
            "\n",
            "**Processing 3 comments...**\n",
            "Test accuracy is 0.2787265443811933\n",
            "\n",
            "\n",
            "**Processing 4 comments...**\n",
            "Test accuracy is 0.2787265443811933\n",
            "\n",
            "\n",
            "**Processing 5 comments...**\n",
            "Test accuracy is 0.2787265443811933\n",
            "\n",
            "\n",
            "**Processing 6 comments...**\n",
            "Test accuracy is 0.2787265443811933\n",
            "\n",
            "\n",
            "**Processing 7 comments...**\n",
            "Test accuracy is 0.2787265443811933\n",
            "\n",
            "\n",
            "**Processing 8 comments...**\n",
            "Test accuracy is 0.2787265443811933\n",
            "\n",
            "\n",
            "**Processing 9 comments...**\n",
            "Test accuracy is 0.2787265443811933\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use ClassifierChain\n",
        "# A chain of binary classifiers C0, C1, . . . , Cn is constructed,\n",
        "# where a classifier Ci uses the predictions of all the classifier Cj , where j < i\n",
        "# The total number of classifiers needed for this approach is equal to the number of classes,\n",
        "# but the training of the classifiers is more involved\n",
        "# Reference: https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff"
      ],
      "metadata": {
        "id": "vnivCRh6yGvH"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Using pipeline for applying logistic regression and one vs rest classifier\n",
        "pipeline = Pipeline([\n",
        "                ('vectorizer',GensimVectorizer(pretrained_vectors)),\n",
        "                ('clf',  ClassifierChain(LogisticRegression()))\n",
        "            ])\n",
        "for category in categories:\n",
        "    print('**Processing {} comments...**'.format(category))\n",
        "    \n",
        "    # Training logistic regression model on train data\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    \n",
        "    # calculating test accuracy\n",
        "    prediction = pipeline.predict(X_test)\n",
        "    print('Test accuracy is {}'.format(accuracy_score(y_test, prediction)))\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlGv7ANkx1V4",
        "outputId": "899c1ba7-0756-4a70-ad12-539b4888e2c7"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Processing 0 comments...**\n",
            "Test accuracy is 0.4174573055028463\n",
            "\n",
            "\n",
            "**Processing 1 comments...**\n",
            "Test accuracy is 0.4174573055028463\n",
            "\n",
            "\n",
            "**Processing 2 comments...**\n",
            "Test accuracy is 0.4174573055028463\n",
            "\n",
            "\n",
            "**Processing 3 comments...**\n",
            "Test accuracy is 0.4174573055028463\n",
            "\n",
            "\n",
            "**Processing 4 comments...**\n",
            "Test accuracy is 0.4174573055028463\n",
            "\n",
            "\n",
            "**Processing 5 comments...**\n",
            "Test accuracy is 0.4174573055028463\n",
            "\n",
            "\n",
            "**Processing 6 comments...**\n",
            "Test accuracy is 0.4174573055028463\n",
            "\n",
            "\n",
            "**Processing 7 comments...**\n",
            "Test accuracy is 0.4174573055028463\n",
            "\n",
            "\n",
            "**Processing 8 comments...**\n",
            "Test accuracy is 0.4174573055028463\n",
            "\n",
            "\n",
            "**Processing 9 comments...**\n",
            "Test accuracy is 0.4174573055028463\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qtJACGSMEPh"
      },
      "source": [
        "# <Font color = 'pickle'>**TASK 5** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiByneM3JxnV"
      },
      "source": [
        "# <font color = 'blue'>Weight Matrix of Pretrained Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-30T02:45:58.138129Z",
          "iopub.status.busy": "2021-06-30T02:45:58.138017Z",
          "iopub.status.idle": "2021-06-30T02:45:58.318850Z",
          "shell.execute_reply": "2021-06-30T02:45:58.318429Z",
          "shell.execute_reply.started": "2021-06-30T02:45:58.138114Z"
        },
        "id": "J2XXdgCgWNlU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "pretrained_vectors = KeyedVectors.load('/content/drive/MyDrive/NLP/Homework6/models/model_cbow.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-06-30T02:45:58.319424Z",
          "iopub.status.busy": "2021-06-30T02:45:58.319323Z",
          "iopub.status.idle": "2021-06-30T02:45:58.377964Z",
          "shell.execute_reply": "2021-06-30T02:45:58.377626Z",
          "shell.execute_reply.started": "2021-06-30T02:45:58.319411Z"
        },
        "id": "yjy2vqMzJxnV",
        "outputId": "0660a00a-51dc-40eb-ab4c-d5ee4cd0ef9d",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "vector = pretrained_vectors.get_vector('office', norm=True)\n",
        "vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-30T02:45:58.378657Z",
          "iopub.status.busy": "2021-06-30T02:45:58.378555Z",
          "iopub.status.idle": "2021-06-30T02:45:58.380890Z",
          "shell.execute_reply": "2021-06-30T02:45:58.380500Z",
          "shell.execute_reply.started": "2021-06-30T02:45:58.378643Z"
        },
        "id": "2TBk2EJ8JxnV",
        "tags": []
      },
      "outputs": [],
      "source": [
        "embedding_dim =150\n",
        "test_weights = np.zeros((2, embedding_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-30T02:45:58.382477Z",
          "iopub.status.busy": "2021-06-30T02:45:58.382369Z",
          "iopub.status.idle": "2021-06-30T02:45:58.384401Z",
          "shell.execute_reply": "2021-06-30T02:45:58.384126Z",
          "shell.execute_reply.started": "2021-06-30T02:45:58.382463Z"
        },
        "id": "dWubBv7LJxnV",
        "tags": []
      },
      "outputs": [],
      "source": [
        "test_weights[0] = pretrained_vectors.get_vector('office', norm=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-30T02:45:58.385063Z",
          "iopub.status.busy": "2021-06-30T02:45:58.384960Z",
          "iopub.status.idle": "2021-06-30T02:45:58.390940Z",
          "shell.execute_reply": "2021-06-30T02:45:58.390590Z",
          "shell.execute_reply.started": "2021-06-30T02:45:58.385050Z"
        },
        "id": "hVf1yJ8FJxnV",
        "tags": []
      },
      "outputs": [],
      "source": [
        "test_weights[1] =  np.random.normal(size=(embedding_dim, ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2021-06-30T02:45:58.391706Z",
          "iopub.status.busy": "2021-06-30T02:45:58.391571Z",
          "iopub.status.idle": "2021-06-30T02:45:58.397242Z",
          "shell.execute_reply": "2021-06-30T02:45:58.396857Z",
          "shell.execute_reply.started": "2021-06-30T02:45:58.391689Z"
        },
        "id": "HOz6iRnJJxnV",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b17b729-ce28-4cb5-c284-e56e9ec4d9d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-6.12220392e-02, -6.43143728e-02, -1.47253862e-02,\n",
              "        -1.68681908e-02, -6.82770163e-02, -5.03983870e-02,\n",
              "         9.00510885e-03,  1.10479690e-01, -3.85514833e-02,\n",
              "        -4.42132428e-02,  1.83668256e-01,  1.81970596e-02,\n",
              "        -6.72796043e-03,  2.67487913e-02,  7.99450949e-02,\n",
              "        -1.51483670e-01,  5.40428795e-02,  3.35344672e-02,\n",
              "        -4.83859368e-02,  9.37992260e-02, -2.63110530e-02,\n",
              "        -1.65316924e-01,  8.53660330e-02, -4.42277566e-02,\n",
              "        -6.09044060e-02, -2.16226317e-02, -1.53136542e-02,\n",
              "         5.85562922e-02,  1.46070585e-01, -8.45404193e-02,\n",
              "         4.10615429e-02, -6.62873238e-02,  6.91241622e-02,\n",
              "        -5.02445959e-02, -5.96107729e-02, -1.06516331e-01,\n",
              "         1.34776114e-02, -5.81563124e-03,  3.57534960e-02,\n",
              "         4.88940924e-02, -9.89808887e-02,  9.90034342e-02,\n",
              "         1.09738089e-01,  7.10285082e-02, -4.50888872e-02,\n",
              "         3.54727288e-03, -9.30363834e-02, -8.72039348e-02,\n",
              "         3.26663516e-02, -1.55520171e-01,  2.53420491e-02,\n",
              "         8.86818245e-02, -4.42792401e-02, -5.02732955e-02,\n",
              "        -2.06673536e-02,  3.97099145e-02,  3.80135030e-02,\n",
              "         1.82009161e-01, -1.30161375e-01, -1.44659253e-02,\n",
              "         4.58315723e-02,  8.09352659e-03,  2.05521611e-03,\n",
              "         2.65751276e-02, -5.52023090e-02, -7.20347241e-02,\n",
              "         1.21202832e-02, -1.07882574e-01,  3.65291419e-03,\n",
              "        -8.22809041e-02,  6.98235929e-02,  6.80745766e-02,\n",
              "         3.48363370e-02,  9.29150507e-02, -1.11451879e-01,\n",
              "        -1.32282466e-01, -2.00030822e-02, -1.83615368e-02,\n",
              "         8.80272985e-02,  1.28395915e-01, -7.01950490e-02,\n",
              "        -4.89731021e-02,  1.06386006e-01, -6.18734257e-03,\n",
              "        -1.16648443e-01, -1.60571877e-02, -8.80076587e-02,\n",
              "        -6.44770265e-02,  8.61187056e-02, -3.56374197e-02,\n",
              "         1.98511537e-02, -1.76975548e-01,  3.22094709e-02,\n",
              "        -5.23201302e-02,  3.12646963e-02, -5.53193390e-02,\n",
              "         3.93999405e-02, -3.79181057e-02, -1.86040699e-02,\n",
              "         8.55109468e-02,  3.97456922e-02, -4.27951403e-02,\n",
              "         1.67984620e-01, -5.31589389e-02,  1.60806924e-01,\n",
              "         5.19003458e-02, -7.83144012e-02,  1.16425797e-01,\n",
              "        -1.45005554e-01, -6.61792234e-02,  5.15389182e-02,\n",
              "         7.22263157e-02, -9.86291468e-02, -2.70440634e-02,\n",
              "         9.12757665e-02,  1.49567872e-02,  6.35119081e-02,\n",
              "        -2.95039807e-02,  1.56396270e-01, -1.63303185e-02,\n",
              "         6.26122132e-02,  1.01852715e-01, -1.34266704e-01,\n",
              "        -2.86244676e-02, -9.68819018e-03, -5.19974418e-02,\n",
              "        -9.87500623e-02,  1.18297875e-01, -7.91054070e-02,\n",
              "        -1.64527327e-01, -5.23377471e-02,  7.96608031e-02,\n",
              "        -6.17654845e-02,  8.22246447e-02,  1.54829293e-01,\n",
              "         3.48234810e-02, -1.76987380e-01, -3.83714326e-02,\n",
              "        -1.12718053e-01,  4.54049446e-02, -4.35751453e-02,\n",
              "         2.98597421e-02,  1.17147818e-01, -2.07625419e-01,\n",
              "         4.29562256e-02, -4.19769548e-02,  9.27577019e-02,\n",
              "         5.04710013e-03, -7.68736526e-02,  3.94994467e-02],\n",
              "       [ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01,\n",
              "         2.24089320e+00,  1.86755799e+00, -9.77277880e-01,\n",
              "         9.50088418e-01, -1.51357208e-01, -1.03218852e-01,\n",
              "         4.10598502e-01,  1.44043571e-01,  1.45427351e+00,\n",
              "         7.61037725e-01,  1.21675016e-01,  4.43863233e-01,\n",
              "         3.33674327e-01,  1.49407907e+00, -2.05158264e-01,\n",
              "         3.13067702e-01, -8.54095739e-01, -2.55298982e+00,\n",
              "         6.53618595e-01,  8.64436199e-01, -7.42165020e-01,\n",
              "         2.26975462e+00, -1.45436567e+00,  4.57585173e-02,\n",
              "        -1.87183850e-01,  1.53277921e+00,  1.46935877e+00,\n",
              "         1.54947426e-01,  3.78162520e-01, -8.87785748e-01,\n",
              "        -1.98079647e+00, -3.47912149e-01,  1.56348969e-01,\n",
              "         1.23029068e+00,  1.20237985e+00, -3.87326817e-01,\n",
              "        -3.02302751e-01, -1.04855297e+00, -1.42001794e+00,\n",
              "        -1.70627019e+00,  1.95077540e+00, -5.09652182e-01,\n",
              "        -4.38074302e-01, -1.25279536e+00,  7.77490356e-01,\n",
              "        -1.61389785e+00, -2.12740280e-01, -8.95466561e-01,\n",
              "         3.86902498e-01, -5.10805138e-01, -1.18063218e+00,\n",
              "        -2.81822283e-02,  4.28331871e-01,  6.65172224e-02,\n",
              "         3.02471898e-01, -6.34322094e-01, -3.62741166e-01,\n",
              "        -6.72460448e-01, -3.59553162e-01, -8.13146282e-01,\n",
              "        -1.72628260e+00,  1.77426142e-01, -4.01780936e-01,\n",
              "        -1.63019835e+00,  4.62782256e-01, -9.07298364e-01,\n",
              "         5.19453958e-02,  7.29090562e-01,  1.28982911e-01,\n",
              "         1.13940068e+00, -1.23482582e+00,  4.02341641e-01,\n",
              "        -6.84810091e-01, -8.70797149e-01, -5.78849665e-01,\n",
              "        -3.11552532e-01,  5.61653422e-02, -1.16514984e+00,\n",
              "         9.00826487e-01,  4.65662440e-01, -1.53624369e+00,\n",
              "         1.48825219e+00,  1.89588918e+00,  1.17877957e+00,\n",
              "        -1.79924836e-01, -1.07075262e+00,  1.05445173e+00,\n",
              "        -4.03176947e-01,  1.22244507e+00,  2.08274978e-01,\n",
              "         9.76639036e-01,  3.56366397e-01,  7.06573168e-01,\n",
              "         1.05000207e-02,  1.78587049e+00,  1.26912093e-01,\n",
              "         4.01989363e-01,  1.88315070e+00, -1.34775906e+00,\n",
              "        -1.27048500e+00,  9.69396708e-01, -1.17312341e+00,\n",
              "         1.94362119e+00, -4.13618981e-01, -7.47454811e-01,\n",
              "         1.92294203e+00,  1.48051479e+00,  1.86755896e+00,\n",
              "         9.06044658e-01, -8.61225685e-01,  1.91006495e+00,\n",
              "        -2.68003371e-01,  8.02456396e-01,  9.47251968e-01,\n",
              "        -1.55010093e-01,  6.14079370e-01,  9.22206672e-01,\n",
              "         3.76425531e-01, -1.09940079e+00,  2.98238174e-01,\n",
              "         1.32638590e+00, -6.94567860e-01, -1.49634540e-01,\n",
              "        -4.35153552e-01,  1.84926373e+00,  6.72294757e-01,\n",
              "         4.07461836e-01, -7.69916074e-01,  5.39249191e-01,\n",
              "        -6.74332661e-01,  3.18305583e-02, -6.35846078e-01,\n",
              "         6.76433295e-01,  5.76590817e-01, -2.08298756e-01,\n",
              "         3.96006713e-01, -1.09306151e+00, -1.49125759e+00,\n",
              "         4.39391701e-01,  1.66673495e-01,  6.35031437e-01,\n",
              "         2.38314477e+00,  9.44479487e-01, -9.12822225e-01,\n",
              "         1.11701629e+00, -1.31590741e+00, -4.61584605e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "test_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-06-30T02:45:58.397963Z",
          "iopub.status.busy": "2021-06-30T02:45:58.397843Z",
          "iopub.status.idle": "2021-06-30T02:45:58.400627Z",
          "shell.execute_reply": "2021-06-30T02:45:58.400360Z",
          "shell.execute_reply.started": "2021-06-30T02:45:58.397947Z"
        },
        "id": "4dcaTAuwJxnW",
        "outputId": "63c7b9a0-733f-42cf-db34-fe1b82a91a7d",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90235"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "len(multilabel_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-30T02:45:58.401175Z",
          "iopub.status.busy": "2021-06-30T02:45:58.401077Z",
          "iopub.status.idle": "2021-06-30T02:46:00.061074Z",
          "shell.execute_reply": "2021-06-30T02:46:00.060592Z",
          "shell.execute_reply.started": "2021-06-30T02:45:58.401162Z"
        },
        "id": "3TzSA-ysJxnW",
        "tags": []
      },
      "outputs": [],
      "source": [
        "embedding_dim = 150\n",
        "pretrained_weights = np.zeros((len(multilabel_vocab), embedding_dim))\n",
        "words_found = 0\n",
        "words_not_found = 0\n",
        "\n",
        "for i, word in enumerate(multilabel_vocab.get_itos()):\n",
        "    try: \n",
        "        pretrained_weights[i] = pretrained_vectors.get_vector(word, norm=True)\n",
        "        words_found += 1\n",
        "    except KeyError:\n",
        "        words_not_found  += 1\n",
        "        pretrained_weights[i] = np.random.normal(size=(embedding_dim, ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-06-30T02:46:00.061675Z",
          "iopub.status.busy": "2021-06-30T02:46:00.061553Z",
          "iopub.status.idle": "2021-06-30T02:46:00.064335Z",
          "shell.execute_reply": "2021-06-30T02:46:00.063980Z",
          "shell.execute_reply.started": "2021-06-30T02:46:00.061661Z"
        },
        "id": "hh1c365fJxnW",
        "outputId": "1bb3c300-bba3-43a8-9364-7121f67b0dc8",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11487"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "words_found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-06-30T02:46:00.064986Z",
          "iopub.status.busy": "2021-06-30T02:46:00.064886Z",
          "iopub.status.idle": "2021-06-30T02:46:00.069909Z",
          "shell.execute_reply": "2021-06-30T02:46:00.069607Z",
          "shell.execute_reply.started": "2021-06-30T02:46:00.064973Z"
        },
        "id": "OIFAKUVIWNlV",
        "outputId": "f6e7e28c-39b1-432c-cb2f-8841a1db2bac",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78748"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "words_not_found"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNseZzQVJD1A"
      },
      "source": [
        "# <Font color = 'pickle'>**Meta Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:10:55.752082Z",
          "iopub.status.busy": "2022-10-24T10:10:55.751573Z",
          "iopub.status.idle": "2022-10-24T10:10:55.777422Z",
          "shell.execute_reply": "2022-10-24T10:10:55.776854Z",
          "shell.execute_reply.started": "2022-10-24T10:10:55.752066Z"
        },
        "tags": [],
        "id": "Pb9BWZQBJD1B"
      },
      "outputs": [],
      "source": [
        "hyperparameters = SimpleNamespace(\n",
        "    EMBED_DIM = 150,\n",
        "    VOCAB_SIZE = len(multilabel_vocab),\n",
        "    OUTPUT_DIM = 10,\n",
        "    HIDDEN_SIZES_LIST = [500,200], # 100 layers of size 200  [200]*100\n",
        "    DPROB_LIST = [0,0],\n",
        "    NON_LINEARITY= nn.SELU(),\n",
        "    PRETRAINED_WEIGHTS_TENSOR = torch.tensor(pretrained_weights).float(),\n",
        "    BATCH_NORM = True,\n",
        "    EPOCHS = 10,\n",
        "    TASK = 5,    \n",
        "    BATCH_SIZE = 256,\n",
        "    LEARNING_RATE = 0.02,\n",
        "    DATASET=\"MultiLabel\",\n",
        "    ARCHITECTUREe=\"2_hidden_layers\",\n",
        "    LOG_INTERVAL = 25,\n",
        "    LOG_BATCH = True,\n",
        "    FILE_MODEL = save_model_folder/'hw6_part_B_full.pt',\n",
        "    GRAD_CLIPPING = False,\n",
        "    MAX_NORM = 0,\n",
        "    MOMENTUM = 0,\n",
        "    PATIENCE = 10,\n",
        "    EARLY_STOPPING = True,\n",
        "    SCHEDULER_FACTOR = 0.5,\n",
        "    SCHEDULER_PATIENCE = 0,\n",
        "    WEIGHT_DECAY = 0.0005,\n",
        "    SAVE_BEST_MODEL = True,\n",
        "    DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f639dc-7f28-48a6-ac47-570d1c927293",
        "id": "foY1Uu8hJD1B"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6Qdv0e1JD1B"
      },
      "source": [
        "# <Font color = 'pickle'>**Data Loaders, Loss Function, Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:10:56.268730Z",
          "iopub.status.busy": "2022-10-24T10:10:56.268433Z",
          "iopub.status.idle": "2022-10-24T10:11:01.517607Z",
          "shell.execute_reply": "2022-10-24T10:11:01.517178Z",
          "shell.execute_reply.started": "2022-10-24T10:10:56.268709Z"
        },
        "outputId": "fe2c455d-a718-4895-91ff-b5c5e1e714ec",
        "tags": [],
        "id": "R4A3wBuKJD1B"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221127_043421-3fxlyvcy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/teffygeorge/NLP_HW6_part2/runs/3fxlyvcy\" target=\"_blank\">task2</a></strong> to <a href=\"https://wandb.ai/teffygeorge/NLP_HW6_part2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/teffygeorge/NLP_HW6_part2/runs/3fxlyvcy?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fd091e872d0>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "# Initialize a new project\n",
        "import random\n",
        "wandb.init(name = 'task2', project = 'NLP_HW6_part2', config = hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.518431Z",
          "iopub.status.busy": "2022-10-24T10:11:01.518292Z",
          "iopub.status.idle": "2022-10-24T10:11:01.543960Z",
          "shell.execute_reply": "2022-10-24T10:11:01.543555Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.518418Z"
        },
        "outputId": "31fe17d1-05ee-4a84-8ea4-7f0e4e74fb23",
        "tags": [],
        "id": "hBtMdyZ-JD1C"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "namespace(ARCHITECTUREe='2_hidden_layers', BATCH_NORM=True, BATCH_SIZE=256, DATASET='MultiLabel', DEVICE=device(type='cuda', index=0), DPROB_LIST=[0, 0], EARLY_STOPPING=True, EMBED_DIM=150, EPOCHS=10, FILE_MODEL=PosixPath('/content/drive/MyDrive/NLP/Homework6/models/hw6_part_B_full.pt'), GRAD_CLIPPING=False, HIDDEN_SIZES_LIST=[500, 200], LEARNING_RATE=0.02, LOG_BATCH=True, LOG_INTERVAL=25, MAX_NORM=0, MOMENTUM=0, NON_LINEARITY=SELU(), OUTPUT_DIM=10, PATIENCE=10, PRETRAINED_WEIGHTS_TENSOR=tensor([[-0.0682,  1.7133, -0.7448,  ...,  0.5830, -0.3994,  0.3701],\n",
              "        [ 0.0588,  0.0114,  0.0397,  ..., -0.1514, -0.0105, -0.0706],\n",
              "        [-0.0205,  0.0141,  0.1818,  ..., -0.1018,  0.0951,  0.0750],\n",
              "        ...,\n",
              "        [ 0.3919,  0.8843, -1.0461,  ...,  0.9146, -1.9827, -0.7953],\n",
              "        [-0.3745,  1.1140, -0.2199,  ..., -1.4224,  0.8445,  1.4767],\n",
              "        [ 0.8993, -0.2509, -1.6339,  ..., -0.7607,  0.8491, -0.0463]]), SAVE_BEST_MODEL=True, SCHEDULER_FACTOR=0.5, SCHEDULER_PATIENCE=0, TASK=5, VOCAB_SIZE=90235, WEIGHT_DECAY=0.0005)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "wandb.config = hyperparameters\n",
        "wandb.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.544753Z",
          "iopub.status.busy": "2022-10-24T10:11:01.544508Z",
          "iopub.status.idle": "2022-10-24T10:11:01.655272Z",
          "shell.execute_reply": "2022-10-24T10:11:01.654814Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.544740Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fee14f6b-823d-42ae-fcd6-0564a60b26d4",
        "id": "Zz0mioeWJD1C"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "# Fix seed value\n",
        "SEED = 2345\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Data Loader\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=wandb.config.BATCH_SIZE, shuffle = True, \n",
        "                                           collate_fn=collate_batch, num_workers = 4)\n",
        "valid_loader = torch.utils.data.DataLoader(validset, batch_size=wandb.config.BATCH_SIZE, shuffle = False, \n",
        "                                           collate_fn=collate_batch,  num_workers = 4)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=wandb.config.BATCH_SIZE,   shuffle = False, \n",
        "                                          collate_fn=collate_batch,  num_workers = 4)\n",
        "\n",
        "# cross entropy loss function\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# model \n",
        "model_multilabel = MLPCustom(wandb.config.EMBED_DIM, \n",
        "                       wandb.config.VOCAB_SIZE, \n",
        "                       wandb.config.HIDDEN_SIZES_LIST, \n",
        "                       wandb.config.DPROB_LIST,\n",
        "                       wandb.config.OUTPUT_DIM, \n",
        "                       wandb.config.NON_LINEARITY,\n",
        "                       wandb.config.BATCH_NORM,\n",
        "                       wandb.config.TASK,\n",
        "                       wandb.config.PRETRAINED_WEIGHTS_TENSOR)\n",
        "\n",
        "model_multilabel.to(wandb.config.DEVICE)\n",
        "\n",
        "def init_weights(m):\n",
        "  if type(m) == nn.Linear:\n",
        "      torch.nn.init.kaiming_normal_(m.weight)\n",
        "      torch.nn.init.zeros_(m.bias)\n",
        "        \n",
        "# apply initialization recursively  to all modules\n",
        "# model_multilabel.apply(init_weights)\n",
        "\n",
        "# Intialize stochiastic gradient descent optimizer\n",
        "optimizer = torch.optim.Adam(model_multilabel.parameters(), \n",
        "                             lr = wandb.config.LEARNING_RATE, \n",
        "                             weight_decay=wandb.config.WEIGHT_DECAY)\n",
        "\n",
        "# wandb.config.OPTIMIZER = optimizer\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor= wandb.config.SCHEDULER_FACTOR, \n",
        "                              patience=wandb.config.SCHEDULER_PATIENCE, verbose=True)\n",
        "\n",
        "#scheduler = StepLR(optimizer, gamma=0.4,step_size=1, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.config.DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c90bcfa-d81a-49c1-d7fd-a0a5e089ff7a",
        "id": "3u0YDq13JD1C"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.656283Z",
          "iopub.status.busy": "2022-10-24T10:11:01.656152Z",
          "iopub.status.idle": "2022-10-24T10:11:01.683125Z",
          "shell.execute_reply": "2022-10-24T10:11:01.682778Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.656271Z"
        },
        "outputId": "b1d49157-4dd7-49bb-9058-8858a888e70d",
        "tags": [],
        "id": "YbLEEMx2JD1C"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "namespace(ARCHITECTUREe='2_hidden_layers', BATCH_NORM=True, BATCH_SIZE=256, DATASET='MultiLabel', DEVICE=device(type='cuda', index=0), DPROB_LIST=[0, 0], EARLY_STOPPING=True, EMBED_DIM=150, EPOCHS=10, FILE_MODEL=PosixPath('/content/drive/MyDrive/NLP/Homework6/models/hw6_part_B_full.pt'), GRAD_CLIPPING=False, HIDDEN_SIZES_LIST=[500, 200], LEARNING_RATE=0.02, LOG_BATCH=True, LOG_INTERVAL=25, MAX_NORM=0, MOMENTUM=0, NON_LINEARITY=SELU(), OUTPUT_DIM=10, PATIENCE=10, PRETRAINED_WEIGHTS_TENSOR=tensor([[-0.0682,  1.7133, -0.7448,  ...,  0.5830, -0.3994,  0.3701],\n",
              "        [ 0.0588,  0.0114,  0.0397,  ..., -0.1514, -0.0105, -0.0706],\n",
              "        [-0.0205,  0.0141,  0.1818,  ..., -0.1018,  0.0951,  0.0750],\n",
              "        ...,\n",
              "        [ 0.3919,  0.8843, -1.0461,  ...,  0.9146, -1.9827, -0.7953],\n",
              "        [-0.3745,  1.1140, -0.2199,  ..., -1.4224,  0.8445,  1.4767],\n",
              "        [ 0.8993, -0.2509, -1.6339,  ..., -0.7607,  0.8491, -0.0463]]), SAVE_BEST_MODEL=True, SCHEDULER_FACTOR=0.5, SCHEDULER_PATIENCE=0, TASK=5, VOCAB_SIZE=90235, WEIGHT_DECAY=0.0005)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "wandb.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_B2RIIHJD1C"
      },
      "source": [
        "# <Font color = 'pickle'>**Sanity Check**\n",
        "- Check the loss without any training. For Cross entropy the expected value will be log(number of classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.683806Z",
          "iopub.status.busy": "2022-10-24T10:11:01.683633Z",
          "iopub.status.idle": "2022-10-24T10:11:01.920580Z",
          "shell.execute_reply": "2022-10-24T10:11:01.920065Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.683793Z"
        },
        "tags": [],
        "id": "HaymFSBaJD1C"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a87d0b-5ea2-4e88-d647-54ad1d7b444e",
        "id": "xcPxkOZBJD1C"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_, targets, offsets in train_loader:\n",
        "  \n",
        "  # move inputs and outputs to GPUs\n",
        "  input_ = input_.to(device)\n",
        "  targets = targets.to(device)\n",
        "  offsets = offsets.to(device)\n",
        "  model_multilabel.eval()\n",
        "  # Forward pass\n",
        "  output = model_multilabel(input_, offsets)\n",
        "  loss = loss_function(output, targets.float())\n",
        "  print(f'Actual loss: {loss}')\n",
        "  break\n",
        "\n",
        "print(f'Expected Theoretical loss: {np.log(2)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08217496-e4a3-4ac0-dd4c-9dad91183c74",
        "id": "fi0WUKnlJD1D"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual loss: 0.6939117312431335\n",
            "Expected Theoretical loss: 0.6931471805599453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIcILgtZJD1D"
      },
      "source": [
        "# <Font color = 'pickle'>**Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.921385Z",
          "iopub.status.busy": "2022-10-24T10:11:01.921236Z",
          "iopub.status.idle": "2022-10-24T10:11:01.957938Z",
          "shell.execute_reply": "2022-10-24T10:11:01.957574Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.921369Z"
        },
        "outputId": "f7e7abb6-1b37-49c2-c9de-071399dd6575",
        "tags": [],
        "id": "ozGxF4UwJD1D"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<wandb.wandb_torch.TorchGraph at 0x7fd091a37910>]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "wandb.watch(model_multilabel, log = 'all', log_freq=25, log_graph=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.958733Z",
          "iopub.status.busy": "2022-10-24T10:11:01.958548Z",
          "iopub.status.idle": "2022-10-24T10:12:09.085757Z",
          "shell.execute_reply": "2022-10-24T10:12:09.085279Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.958718Z"
        },
        "tags": [],
        "outputId": "dbc0d726-31a9-483d-81c3-b5101cfebf64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IHfb_PDJD1D"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (inf --> 0.255687). Saving Model...\n",
            "Epoch : 1 / 10\n",
            "Time to complete 1 is 0:00:06.820830\n",
            "Learning rate: 0.02\n",
            "Train Loss:  0.3005 \n",
            "Valid Loss:  0.2557 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.255687 --> 0.248233). Saving model...\n",
            "Epoch : 2 / 10\n",
            "Time to complete 2 is 0:00:06.691172\n",
            "Learning rate: 0.02\n",
            "Train Loss:  0.2476 \n",
            "Valid Loss:  0.2482 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00003: reducing learning rate of group 0 to 1.0000e-02.\n",
            "Early stoping counter: 1 out of 10\n",
            "Epoch : 3 / 10\n",
            "Time to complete 3 is 0:00:06.716062\n",
            "Learning rate: 0.01\n",
            "Train Loss:  0.2428 \n",
            "Valid Loss:  0.2996 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.248233 --> 0.225125). Saving model...\n",
            "Epoch : 4 / 10\n",
            "Time to complete 4 is 0:00:06.758438\n",
            "Learning rate: 0.01\n",
            "Train Loss:  0.2367 \n",
            "Valid Loss:  0.2251 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.225125 --> 0.225097). Saving model...\n",
            "Epoch : 5 / 10\n",
            "Time to complete 5 is 0:00:06.635655\n",
            "Learning rate: 0.01\n",
            "Train Loss:  0.2348 \n",
            "Valid Loss:  0.2251 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00006: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Early stoping counter: 1 out of 10\n",
            "Epoch : 6 / 10\n",
            "Time to complete 6 is 0:00:06.671038\n",
            "Learning rate: 0.005\n",
            "Train Loss:  0.2344 \n",
            "Valid Loss:  0.2304 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.225097 --> 0.224271). Saving model...\n",
            "Epoch : 7 / 10\n",
            "Time to complete 7 is 0:00:06.829370\n",
            "Learning rate: 0.005\n",
            "Train Loss:  0.2288 \n",
            "Valid Loss:  0.2243 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.224271 --> 0.218827). Saving model...\n",
            "Epoch : 8 / 10\n",
            "Time to complete 8 is 0:00:06.669182\n",
            "Learning rate: 0.005\n",
            "Train Loss:  0.2282 \n",
            "Valid Loss:  0.2188 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00009: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Early stoping counter: 1 out of 10\n",
            "Epoch : 9 / 10\n",
            "Time to complete 9 is 0:00:06.809452\n",
            "Learning rate: 0.0025\n",
            "Train Loss:  0.2291 \n",
            "Valid Loss:  0.2423 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00010: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Early stoping counter: 2 out of 10\n",
            "Epoch : 10 / 10\n",
            "Time to complete 10 is 0:00:06.893529\n",
            "Learning rate: 0.00125\n",
            "Train Loss:  0.2256 \n",
            "Valid Loss:  0.2197 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# See live graphs in the notebook.\n",
        "#%%wandb \n",
        "# See live graphs in the notebook.\n",
        "#%%wandb \n",
        "batch_ct_train, batch_ct_valid = 0, 0\n",
        "train_loss_history, valid_loss_history = train_loop(train_loader, \n",
        "                                                     valid_loader, \n",
        "                                                                                          model_multilabel, \n",
        "                                                                                          optimizer,\n",
        "                                                                                          loss_function, \n",
        "                                                                                          wandb.config.EPOCHS, \n",
        "                                                                                          wandb.config.DEVICE,\n",
        "                                                                                          wandb.config.PATIENCE, \n",
        "                                                                                          wandb.config.EARLY_STOPPING,\n",
        "                                                                                          wandb.config.FILE_MODEL,\n",
        "                                                                                          wandb.config.SAVE_BEST_MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIjbQEvAJD1D"
      },
      "source": [
        "# <Font color = 'pickle'>**Get Accuracy, Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:12:09.086719Z",
          "iopub.status.busy": "2022-10-24T10:12:09.086506Z",
          "iopub.status.idle": "2022-10-24T10:12:09.119252Z",
          "shell.execute_reply": "2022-10-24T10:12:09.118859Z",
          "shell.execute_reply.started": "2022-10-24T10:12:09.086701Z"
        },
        "outputId": "a19332f9-5a24-4ba0-f116-7e73f5ae6dac",
        "tags": [],
        "id": "jNi7An-pJD1D"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:12:09.120013Z",
          "iopub.status.busy": "2022-10-24T10:12:09.119827Z",
          "iopub.status.idle": "2022-10-24T10:12:09.259339Z",
          "shell.execute_reply": "2022-10-24T10:12:09.258892Z",
          "shell.execute_reply.started": "2022-10-24T10:12:09.119999Z"
        },
        "outputId": "5b336f05-26e5-4605-d3b7-673655e05ece",
        "tags": [],
        "id": "pLc3J9unJD1D"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "model_nn = MLPCustom(wandb.config.EMBED_DIM, \n",
        "                       wandb.config.VOCAB_SIZE, \n",
        "                       wandb.config.HIDDEN_SIZES_LIST, \n",
        "                       wandb.config.DPROB_LIST,\n",
        "                       wandb.config.OUTPUT_DIM, \n",
        "                       wandb.config.NON_LINEARITY,\n",
        "                       wandb.config.BATCH_NORM,\n",
        "                       wandb.config.TASK,\n",
        "                       wandb.config.PRETRAINED_WEIGHTS_TENSOR)\n",
        "model_nn.to(wandb.config.DEVICE)\n",
        "model_nn.load_state_dict(torch.load(wandb.config.FILE_MODEL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:12:09.260788Z",
          "iopub.status.busy": "2022-10-24T10:12:09.260622Z",
          "iopub.status.idle": "2022-10-24T10:12:10.954206Z",
          "shell.execute_reply": "2022-10-24T10:12:10.953655Z",
          "shell.execute_reply.started": "2022-10-24T10:12:09.260776Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc03b96-8248-4c04-ed68-5438bb4d4a2c",
        "id": "brHJml6dJD1E"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ],
      "source": [
        "# Get the prediction and labels\n",
        "y_train,  y_predicted_train = get_pred(train_loader, model_nn)\n",
        "y_valid, y_predicted_valid = get_pred(valid_loader, model_nn)\n",
        "y_test,  y_predicted_test  = get_pred(test_loader, model_nn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1score  = F1Score(num_classes=10, mdmc_average= 'global').to(device)"
      ],
      "metadata": {
        "id": "1W8gcmOlJD1E"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_f1_score = f1score( y_predicted_train, y_train.long())"
      ],
      "metadata": {
        "id": "ySoYl3pqJD1E"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_f1_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57b5f19-e92a-49cb-fd35-b007c14fb297",
        "id": "rab_H-78JD1E"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7647, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert these to numpy array\n",
        "y_train, y_predicted_train  = y_train.cpu().numpy(), y_predicted_train.cpu().numpy() \n",
        "y_valid, y_predicted_valid  = y_valid.cpu().numpy(), y_predicted_valid.cpu().numpy() \n",
        "y_test, y_predicted_test  = y_test.cpu().numpy(), y_predicted_test.cpu().numpy() "
      ],
      "metadata": {
        "id": "gLOBL_OuJD1E"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "eWfm50IeJD1E"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_train = f1_score(y_train, y_predicted_train, average = 'micro')\n",
        "f1_score_valid = f1_score(y_valid, y_predicted_valid, average = 'micro')\n",
        "f1_score_test = f1_score(y_test, y_predicted_test, average = 'micro')"
      ],
      "metadata": {
        "id": "IuhIn3A4JD1F"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Accuracy based on saved Model\n",
        "print('f1_score_train', f1_score_train)\n",
        "print('f1_score_valid', f1_score_valid)\n",
        "print('f1_score_test', f1_score_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b23747-8990-4199-9ade-d0d28bb5d345",
        "id": "qRqlIIApJD1F"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score_train 0.7647206483540128\n",
            "f1_score_valid 0.7733948690104521\n",
            "f1_score_test 0.7722659430122117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.log({'Train f1 score': f1_score_train})\n",
        "wandb.log({'Valid f1 score': f1_score_valid}) \n",
        "wandb.log({'Test f1 score': f1_score_test})"
      ],
      "metadata": {
        "id": "6IxlnbxkJD1F"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "9f27acd9-7c43-4e91-8917-135db807826f",
        "id": "Cr15RbohJD1F"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test f1 score</td><td>▁</td></tr><tr><td>Train Batch Loss  :</td><td>▇█▅▅▅▄▆▅▇▇▄▆▄▄▃█▄▃▇▄▄▃▅▄▃▃▅▃▁▂▂▄▃▂▃▃▄▄▄▅</td></tr><tr><td>Train Loss :</td><td>█▃▃▂▂▂▁▁▁▁</td></tr><tr><td>Train f1 score</td><td>▁</td></tr><tr><td>Valid Batch Loss  :</td><td>▇▅▄█▄▁▂▃▄▂▂▂▆▂▂</td></tr><tr><td>Valid Loss :</td><td>▄▄█▂▂▂▁▁▃▁</td></tr><tr><td>Valid f1 score</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test f1 score</td><td>0.77227</td></tr><tr><td>Train Batch Loss  :</td><td>0.24631</td></tr><tr><td>Train Loss :</td><td>0.22556</td></tr><tr><td>Train f1 score</td><td>0.76472</td></tr><tr><td>Valid Batch Loss  :</td><td>0.21281</td></tr><tr><td>Valid Loss :</td><td>0.21966</td></tr><tr><td>Valid f1 score</td><td>0.77339</td></tr><tr><td>epoch</td><td>9</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">task2</strong>: <a href=\"https://wandb.ai/teffygeorge/NLP_HW6_part2/runs/3fxlyvcy\" target=\"_blank\">https://wandb.ai/teffygeorge/NLP_HW6_part2/runs/3fxlyvcy</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221127_043421-3fxlyvcy/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvFLht0yMKZ2"
      },
      "source": [
        "# <Font color = 'pickle'>**TASK 6** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0lJZHCyLizt"
      },
      "source": [
        "# <Font color = 'pickle'>**Meta Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:10:55.752082Z",
          "iopub.status.busy": "2022-10-24T10:10:55.751573Z",
          "iopub.status.idle": "2022-10-24T10:10:55.777422Z",
          "shell.execute_reply": "2022-10-24T10:10:55.776854Z",
          "shell.execute_reply.started": "2022-10-24T10:10:55.752066Z"
        },
        "tags": [],
        "id": "EmYHzsWLLizu"
      },
      "outputs": [],
      "source": [
        "hyperparameters = SimpleNamespace(\n",
        "    EMBED_DIM = 150,\n",
        "    VOCAB_SIZE = len(multilabel_vocab),\n",
        "    OUTPUT_DIM = 10,\n",
        "    HIDDEN_SIZES_LIST = [500,200], # 100 layers of size 200  [200]*100\n",
        "    DPROB_LIST = [0,0],\n",
        "    NON_LINEARITY= nn.SELU(),\n",
        "    PRETRAINED_WEIGHTS_TENSOR = torch.tensor(pretrained_weights).float(),\n",
        "    BATCH_NORM = True,\n",
        "    EPOCHS = 10,\n",
        "    TASK = 6,    \n",
        "    BATCH_SIZE = 256,\n",
        "    LEARNING_RATE = 0.02,\n",
        "    DATASET=\"MultiLabel\",\n",
        "    ARCHITECTUREe=\"2_hidden_layers\",\n",
        "    LOG_INTERVAL = 25,\n",
        "    LOG_BATCH = True,\n",
        "    FILE_MODEL = save_model_folder/'hw6_part_B_full.pt',\n",
        "    GRAD_CLIPPING = False,\n",
        "    MAX_NORM = 0,\n",
        "    MOMENTUM = 0,\n",
        "    PATIENCE = 10,\n",
        "    EARLY_STOPPING = True,\n",
        "    SCHEDULER_FACTOR = 0.5,\n",
        "    SCHEDULER_PATIENCE = 0,\n",
        "    WEIGHT_DECAY = 0.0005,\n",
        "    SAVE_BEST_MODEL = True,\n",
        "    DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c513357-ab40-4425-8d16-62ea9aa7cae2",
        "id": "mNevUwRqLizu"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8mOkyutLizu"
      },
      "source": [
        "# <Font color = 'pickle'>**Data Loaders, Loss Function, Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:10:56.268730Z",
          "iopub.status.busy": "2022-10-24T10:10:56.268433Z",
          "iopub.status.idle": "2022-10-24T10:11:01.517607Z",
          "shell.execute_reply": "2022-10-24T10:11:01.517178Z",
          "shell.execute_reply.started": "2022-10-24T10:10:56.268709Z"
        },
        "outputId": "9b90e843-c92d-44c9-b3a7-16c3e81cd7df",
        "tags": [],
        "id": "6BmC9csLLizu"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221127_043723-xxbxpy3m</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/teffygeorge/NLP_HW6_part2/runs/xxbxpy3m\" target=\"_blank\">task2</a></strong> to <a href=\"https://wandb.ai/teffygeorge/NLP_HW6_part2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/teffygeorge/NLP_HW6_part2/runs/xxbxpy3m?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fd091b0e310>"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "# Initialize a new project\n",
        "import random\n",
        "wandb.init(name = 'task2', project = 'NLP_HW6_part2', config = hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.518431Z",
          "iopub.status.busy": "2022-10-24T10:11:01.518292Z",
          "iopub.status.idle": "2022-10-24T10:11:01.543960Z",
          "shell.execute_reply": "2022-10-24T10:11:01.543555Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.518418Z"
        },
        "outputId": "a851731a-6551-4201-9f6b-3f2bdd3ec06f",
        "tags": [],
        "id": "srfif2aNLizv"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "namespace(ARCHITECTUREe='2_hidden_layers', BATCH_NORM=True, BATCH_SIZE=256, DATASET='MultiLabel', DEVICE=device(type='cuda', index=0), DPROB_LIST=[0, 0], EARLY_STOPPING=True, EMBED_DIM=150, EPOCHS=10, FILE_MODEL=PosixPath('/content/drive/MyDrive/NLP/Homework6/models/hw6_part_B_full.pt'), GRAD_CLIPPING=False, HIDDEN_SIZES_LIST=[500, 200], LEARNING_RATE=0.02, LOG_BATCH=True, LOG_INTERVAL=25, MAX_NORM=0, MOMENTUM=0, NON_LINEARITY=SELU(), OUTPUT_DIM=10, PATIENCE=10, PRETRAINED_WEIGHTS_TENSOR=tensor([[-0.0682,  1.7133, -0.7448,  ...,  0.5830, -0.3994,  0.3701],\n",
              "        [ 0.0588,  0.0114,  0.0397,  ..., -0.1514, -0.0105, -0.0706],\n",
              "        [-0.0205,  0.0141,  0.1818,  ..., -0.1018,  0.0951,  0.0750],\n",
              "        ...,\n",
              "        [ 0.3919,  0.8843, -1.0461,  ...,  0.9146, -1.9827, -0.7953],\n",
              "        [-0.3745,  1.1140, -0.2199,  ..., -1.4224,  0.8445,  1.4767],\n",
              "        [ 0.8993, -0.2509, -1.6339,  ..., -0.7607,  0.8491, -0.0463]]), SAVE_BEST_MODEL=True, SCHEDULER_FACTOR=0.5, SCHEDULER_PATIENCE=0, TASK=6, VOCAB_SIZE=90235, WEIGHT_DECAY=0.0005)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "wandb.config = hyperparameters\n",
        "wandb.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.544753Z",
          "iopub.status.busy": "2022-10-24T10:11:01.544508Z",
          "iopub.status.idle": "2022-10-24T10:11:01.655272Z",
          "shell.execute_reply": "2022-10-24T10:11:01.654814Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.544740Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVQ74gz2Lizv",
        "outputId": "93845ae2-6fed-4fb8-e297-2e6702138b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "# Fix seed value\n",
        "SEED = 2345\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Data Loader\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=wandb.config.BATCH_SIZE, shuffle = True, \n",
        "                                           collate_fn=collate_batch, num_workers = 4)\n",
        "valid_loader = torch.utils.data.DataLoader(validset, batch_size=wandb.config.BATCH_SIZE, shuffle = False, \n",
        "                                           collate_fn=collate_batch,  num_workers = 4)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=wandb.config.BATCH_SIZE,   shuffle = False, \n",
        "                                          collate_fn=collate_batch,  num_workers = 4)\n",
        "\n",
        "# cross entropy loss function\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# model \n",
        "model_multilabel = MLPCustom(wandb.config.EMBED_DIM, \n",
        "                       wandb.config.VOCAB_SIZE, \n",
        "                       wandb.config.HIDDEN_SIZES_LIST, \n",
        "                       wandb.config.DPROB_LIST,\n",
        "                       wandb.config.OUTPUT_DIM, \n",
        "                       wandb.config.NON_LINEARITY,\n",
        "                       wandb.config.BATCH_NORM,\n",
        "                       wandb.config.TASK,\n",
        "                       wandb.config.PRETRAINED_WEIGHTS_TENSOR)\n",
        "\n",
        "model_multilabel.to(wandb.config.DEVICE)\n",
        "\n",
        "def init_weights(m):\n",
        "  if type(m) == nn.Linear:\n",
        "      torch.nn.init.kaiming_normal_(m.weight)\n",
        "      torch.nn.init.zeros_(m.bias)\n",
        "        \n",
        "# apply initialization recursively  to all modules\n",
        "# model_multilabel.apply(init_weights)\n",
        "\n",
        "# Intialize stochiastic gradient descent optimizer\n",
        "optimizer = torch.optim.Adam(model_multilabel.parameters(), \n",
        "                             lr = wandb.config.LEARNING_RATE, \n",
        "                             weight_decay=wandb.config.WEIGHT_DECAY)\n",
        "\n",
        "# wandb.config.OPTIMIZER = optimizer\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor= wandb.config.SCHEDULER_FACTOR, \n",
        "                              patience=wandb.config.SCHEDULER_PATIENCE, verbose=True)\n",
        "\n",
        "#scheduler = StepLR(optimizer, gamma=0.4,step_size=1, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.config.DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb353ab-7529-4d7e-affa-b37b995edc05",
        "id": "hHm3L5pmLizv"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.656283Z",
          "iopub.status.busy": "2022-10-24T10:11:01.656152Z",
          "iopub.status.idle": "2022-10-24T10:11:01.683125Z",
          "shell.execute_reply": "2022-10-24T10:11:01.682778Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.656271Z"
        },
        "outputId": "26254887-722e-4c02-edb9-11797ddff255",
        "tags": [],
        "id": "gWeb5qI-Lizv"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "namespace(ARCHITECTUREe='2_hidden_layers', BATCH_NORM=True, BATCH_SIZE=256, DATASET='MultiLabel', DEVICE=device(type='cuda', index=0), DPROB_LIST=[0, 0], EARLY_STOPPING=True, EMBED_DIM=150, EPOCHS=10, FILE_MODEL=PosixPath('/content/drive/MyDrive/NLP/Homework6/models/hw6_part_B_full.pt'), GRAD_CLIPPING=False, HIDDEN_SIZES_LIST=[500, 200], LEARNING_RATE=0.02, LOG_BATCH=True, LOG_INTERVAL=25, MAX_NORM=0, MOMENTUM=0, NON_LINEARITY=SELU(), OUTPUT_DIM=10, PATIENCE=10, PRETRAINED_WEIGHTS_TENSOR=tensor([[-0.0682,  1.7133, -0.7448,  ...,  0.5830, -0.3994,  0.3701],\n",
              "        [ 0.0588,  0.0114,  0.0397,  ..., -0.1514, -0.0105, -0.0706],\n",
              "        [-0.0205,  0.0141,  0.1818,  ..., -0.1018,  0.0951,  0.0750],\n",
              "        ...,\n",
              "        [ 0.3919,  0.8843, -1.0461,  ...,  0.9146, -1.9827, -0.7953],\n",
              "        [-0.3745,  1.1140, -0.2199,  ..., -1.4224,  0.8445,  1.4767],\n",
              "        [ 0.8993, -0.2509, -1.6339,  ..., -0.7607,  0.8491, -0.0463]]), SAVE_BEST_MODEL=True, SCHEDULER_FACTOR=0.5, SCHEDULER_PATIENCE=0, TASK=6, VOCAB_SIZE=90235, WEIGHT_DECAY=0.0005)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "wandb.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi3GP0D6Lizv"
      },
      "source": [
        "# <Font color = 'pickle'>**Sanity Check**\n",
        "- Check the loss without any training. For Cross entropy the expected value will be log(number of classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.683806Z",
          "iopub.status.busy": "2022-10-24T10:11:01.683633Z",
          "iopub.status.idle": "2022-10-24T10:11:01.920580Z",
          "shell.execute_reply": "2022-10-24T10:11:01.920065Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.683793Z"
        },
        "tags": [],
        "id": "Girg29JqLizv"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "363d5f42-d268-4647-b2bf-02a55c2f6302",
        "id": "OWdIU9R8Lizv"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_, targets, offsets in train_loader:\n",
        "  \n",
        "  # move inputs and outputs to GPUs\n",
        "  input_ = input_.to(device)\n",
        "  targets = targets.to(device)\n",
        "  offsets = offsets.to(device)\n",
        "  model_multilabel.eval()\n",
        "  # Forward pass\n",
        "  output = model_multilabel(input_, offsets)\n",
        "  loss = loss_function(output, targets.float())\n",
        "  print(f'Actual loss: {loss}')\n",
        "  break\n",
        "\n",
        "print(f'Expected Theoretical loss: {np.log(2)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175f26eb-f95c-4f73-c626-6e9ef7c346a6",
        "id": "-AQesoFRLizv"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual loss: 0.6945945620536804\n",
            "Expected Theoretical loss: 0.6931471805599453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sksrVouLLizw"
      },
      "source": [
        "# <Font color = 'pickle'>**Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.921385Z",
          "iopub.status.busy": "2022-10-24T10:11:01.921236Z",
          "iopub.status.idle": "2022-10-24T10:11:01.957938Z",
          "shell.execute_reply": "2022-10-24T10:11:01.957574Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.921369Z"
        },
        "outputId": "79050c60-785d-446a-c083-db64ef0d23c9",
        "tags": [],
        "id": "ZFHxgK-rLizw"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<wandb.wandb_torch.TorchGraph at 0x7fd0915a4250>]"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "wandb.watch(model_multilabel, log = 'all', log_freq=25, log_graph=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:11:01.958733Z",
          "iopub.status.busy": "2022-10-24T10:11:01.958548Z",
          "iopub.status.idle": "2022-10-24T10:12:09.085757Z",
          "shell.execute_reply": "2022-10-24T10:12:09.085279Z",
          "shell.execute_reply.started": "2022-10-24T10:11:01.958718Z"
        },
        "tags": [],
        "outputId": "b49c5ede-e6c2-4dd5-b7a3-45b764c005ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIN5SplELizw"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (inf --> 0.192825). Saving Model...\n",
            "Epoch : 1 / 10\n",
            "Time to complete 1 is 0:00:07.229786\n",
            "Learning rate: 0.02\n",
            "Train Loss:  0.2430 \n",
            "Valid Loss:  0.1928 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.192825 --> 0.151609). Saving model...\n",
            "Epoch : 2 / 10\n",
            "Time to complete 2 is 0:00:07.118540\n",
            "Learning rate: 0.02\n",
            "Train Loss:  0.1570 \n",
            "Valid Loss:  0.1516 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00003: reducing learning rate of group 0 to 1.0000e-02.\n",
            "Early stoping counter: 1 out of 10\n",
            "Epoch : 3 / 10\n",
            "Time to complete 3 is 0:00:07.142046\n",
            "Learning rate: 0.01\n",
            "Train Loss:  0.1406 \n",
            "Valid Loss:  0.1651 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.151609 --> 0.126412). Saving model...\n",
            "Epoch : 4 / 10\n",
            "Time to complete 4 is 0:00:07.272406\n",
            "Learning rate: 0.01\n",
            "Train Loss:  0.1244 \n",
            "Valid Loss:  0.1264 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00005: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Early stoping counter: 1 out of 10\n",
            "Epoch : 5 / 10\n",
            "Time to complete 5 is 0:00:07.206813\n",
            "Learning rate: 0.005\n",
            "Train Loss:  0.1200 \n",
            "Valid Loss:  0.1342 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.126412 --> 0.121033). Saving model...\n",
            "Epoch : 6 / 10\n",
            "Time to complete 6 is 0:00:07.386245\n",
            "Learning rate: 0.005\n",
            "Train Loss:  0.1044 \n",
            "Valid Loss:  0.1210 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.121033 --> 0.119801). Saving model...\n",
            "Epoch : 7 / 10\n",
            "Time to complete 7 is 0:00:07.170740\n",
            "Learning rate: 0.005\n",
            "Train Loss:  0.1000 \n",
            "Valid Loss:  0.1198 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00008: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Early stoping counter: 1 out of 10\n",
            "Epoch : 8 / 10\n",
            "Time to complete 8 is 0:00:07.131865\n",
            "Learning rate: 0.0025\n",
            "Train Loss:  0.0976 \n",
            "Valid Loss:  0.1288 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (0.119801 --> 0.115113). Saving model...\n",
            "Epoch : 9 / 10\n",
            "Time to complete 9 is 0:00:07.318225\n",
            "Learning rate: 0.0025\n",
            "Train Loss:  0.0858 \n",
            "Valid Loss:  0.1151 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00010: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Early stoping counter: 1 out of 10\n",
            "Epoch : 10 / 10\n",
            "Time to complete 10 is 0:00:07.163806\n",
            "Learning rate: 0.00125\n",
            "Train Loss:  0.0805 \n",
            "Valid Loss:  0.1232 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# See live graphs in the notebook.\n",
        "#%%wandb \n",
        "# See live graphs in the notebook.\n",
        "#%%wandb \n",
        "batch_ct_train, batch_ct_valid = 0, 0\n",
        "train_loss_history, valid_loss_history = train_loop(train_loader, \n",
        "                                                     valid_loader, \n",
        "                                                                                          model_multilabel, \n",
        "                                                                                          optimizer,\n",
        "                                                                                          loss_function, \n",
        "                                                                                          wandb.config.EPOCHS, \n",
        "                                                                                          wandb.config.DEVICE,\n",
        "                                                                                          wandb.config.PATIENCE, \n",
        "                                                                                          wandb.config.EARLY_STOPPING,\n",
        "                                                                                          wandb.config.FILE_MODEL,\n",
        "                                                                                          wandb.config.SAVE_BEST_MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tO_s4y3Lizw"
      },
      "source": [
        "# <Font color = 'pickle'>**Get Accuracy, Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:12:09.086719Z",
          "iopub.status.busy": "2022-10-24T10:12:09.086506Z",
          "iopub.status.idle": "2022-10-24T10:12:09.119252Z",
          "shell.execute_reply": "2022-10-24T10:12:09.118859Z",
          "shell.execute_reply.started": "2022-10-24T10:12:09.086701Z"
        },
        "outputId": "558a43de-dcc4-456d-8e16-20f61e053eb6",
        "tags": [],
        "id": "8n5ymz7DLizw"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T10:12:09.120013Z",
          "iopub.status.busy": "2022-10-24T10:12:09.119827Z",
          "iopub.status.idle": "2022-10-24T10:12:09.259339Z",
          "shell.execute_reply": "2022-10-24T10:12:09.258892Z",
          "shell.execute_reply.started": "2022-10-24T10:12:09.119999Z"
        },
        "outputId": "02aa4671-450b-4ff2-be1f-8a8ff0db203c",
        "tags": [],
        "id": "4xNxyA2DLizw"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "model_nn = MLPCustom(wandb.config.EMBED_DIM, \n",
        "                       wandb.config.VOCAB_SIZE, \n",
        "                       wandb.config.HIDDEN_SIZES_LIST, \n",
        "                       wandb.config.DPROB_LIST,\n",
        "                       wandb.config.OUTPUT_DIM, \n",
        "                       wandb.config.NON_LINEARITY,\n",
        "                       wandb.config.BATCH_NORM,\n",
        "                       wandb.config.TASK,\n",
        "                       wandb.config.PRETRAINED_WEIGHTS_TENSOR)\n",
        "model_nn.to(wandb.config.DEVICE)\n",
        "model_nn.load_state_dict(torch.load(wandb.config.FILE_MODEL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T10:12:09.260788Z",
          "iopub.status.busy": "2022-10-24T10:12:09.260622Z",
          "iopub.status.idle": "2022-10-24T10:12:10.954206Z",
          "shell.execute_reply": "2022-10-24T10:12:10.953655Z",
          "shell.execute_reply.started": "2022-10-24T10:12:09.260776Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c4eba1-cd2b-430a-bc8a-1c828a0bed4b",
        "id": "DvRfdvaCLizw"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ],
      "source": [
        "# Get the prediction and labels\n",
        "y_train,  y_predicted_train = get_pred(train_loader, model_nn)\n",
        "y_valid, y_predicted_valid = get_pred(valid_loader, model_nn)\n",
        "y_test,  y_predicted_test  = get_pred(test_loader, model_nn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1score  = F1Score(num_classes=10, mdmc_average= 'global').to(device)"
      ],
      "metadata": {
        "id": "z_3z0O1zLizx"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_f1_score = f1score( y_predicted_train, y_train.long())"
      ],
      "metadata": {
        "id": "j69l9cEnLizx"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_f1_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70dafd17-0566-418d-c733-916712c43b79",
        "id": "EHM1cdRBLizx"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9351, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert these to numpy array\n",
        "y_train, y_predicted_train  = y_train.cpu().numpy(), y_predicted_train.cpu().numpy() \n",
        "y_valid, y_predicted_valid  = y_valid.cpu().numpy(), y_predicted_valid.cpu().numpy() \n",
        "y_test, y_predicted_test  = y_test.cpu().numpy(), y_predicted_test.cpu().numpy() "
      ],
      "metadata": {
        "id": "L0If1MaeLizx"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "qF27yYFQLizx"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_train = f1_score(y_train, y_predicted_train, average = 'micro')\n",
        "f1_score_valid = f1_score(y_valid, y_predicted_valid, average = 'micro')\n",
        "f1_score_test = f1_score(y_test, y_predicted_test, average = 'micro')"
      ],
      "metadata": {
        "id": "Sr58xrmxLizx"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Accuracy based on saved Model\n",
        "print('f1_score_train', f1_score_train)\n",
        "print('f1_score_valid', f1_score_valid)\n",
        "print('f1_score_test', f1_score_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b40e30-8a92-48e8-f3af-be380c5eff31",
        "id": "35rEgePBLizx"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score_train 0.9350741419034677\n",
            "f1_score_valid 0.9010492086477148\n",
            "f1_score_test 0.8955049323705888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.log({'Train f1 score': f1_score_train})\n",
        "wandb.log({'Valid f1 score': f1_score_valid}) \n",
        "wandb.log({'Test f1 score': f1_score_test})"
      ],
      "metadata": {
        "id": "5as8TifuLizx"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "c7532a49-225e-4e26-9388-539b637e94fb",
        "id": "rjcIYvt-Lizx"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test f1 score</td><td>▁</td></tr><tr><td>Train Batch Loss  :</td><td>█▅▆▄▄▄▄▃▇▄▄▃▃▃▂▃▂▂▃▃▂▂▁▂▁▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁</td></tr><tr><td>Train Loss :</td><td>█▄▄▃▃▂▂▂▁▁</td></tr><tr><td>Train f1 score</td><td>▁</td></tr><tr><td>Valid Batch Loss  :</td><td>█▅▂▆▄▁▂▂▂▂▃▁▂▃▂</td></tr><tr><td>Valid Loss :</td><td>█▄▆▂▃▂▁▂▁▂</td></tr><tr><td>Valid f1 score</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test f1 score</td><td>0.8955</td></tr><tr><td>Train Batch Loss  :</td><td>0.07647</td></tr><tr><td>Train Loss :</td><td>0.08047</td></tr><tr><td>Train f1 score</td><td>0.93507</td></tr><tr><td>Valid Batch Loss  :</td><td>0.11418</td></tr><tr><td>Valid Loss :</td><td>0.12316</td></tr><tr><td>Valid f1 score</td><td>0.90105</td></tr><tr><td>epoch</td><td>9</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">task2</strong>: <a href=\"https://wandb.ai/teffygeorge/NLP_HW6_part2/runs/xxbxpy3m\" target=\"_blank\">https://wandb.ai/teffygeorge/NLP_HW6_part2/runs/xxbxpy3m</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221127_043723-xxbxpy3m/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "zvFLht0yMKZ2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c58a79bec31149a2a450668b65c7b6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_556af826137f43f2ace4ce2e2375f634",
              "IPY_MODEL_bb9a8cce0fc6448b91ec8eb63330ddd3"
            ],
            "layout": "IPY_MODEL_3a4953de045c46eb9ebf5f963b88cbcd"
          }
        },
        "556af826137f43f2ace4ce2e2375f634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d243366b5d55441589e0d4b7b8e13383",
            "placeholder": "​",
            "style": "IPY_MODEL_23d5f8b7ceb54495913ddfbd8a4487ab",
            "value": "0.001 MB of 0.003 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "bb9a8cce0fc6448b91ec8eb63330ddd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_345432f73833446984a9fc9129b87cc8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef0bec2ba12a4594b3e4e379cb7c3280",
            "value": 0.2585034013605442
          }
        },
        "3a4953de045c46eb9ebf5f963b88cbcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d243366b5d55441589e0d4b7b8e13383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23d5f8b7ceb54495913ddfbd8a4487ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "345432f73833446984a9fc9129b87cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef0bec2ba12a4594b3e4e379cb7c3280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "621aab630d574925943bd5fc50480e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a8c789140d5456886071fab75b2aca6",
              "IPY_MODEL_efe70104a7ae4acfb9ec58c2dcf04fe7"
            ],
            "layout": "IPY_MODEL_543bba70ecf84e26acf25bb4aeb3ef31"
          }
        },
        "9a8c789140d5456886071fab75b2aca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e7e3fcbd69b4cc8bf1d76f4bb8f3b88",
            "placeholder": "​",
            "style": "IPY_MODEL_257e853d3639423db749699c1f696241",
            "value": "0.086 MB of 0.086 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "efe70104a7ae4acfb9ec58c2dcf04fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03048ef4a2384bd4b602ef294cfecc56",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88f8c08d2e11459a8eda6be724e12e06",
            "value": 1
          }
        },
        "543bba70ecf84e26acf25bb4aeb3ef31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e7e3fcbd69b4cc8bf1d76f4bb8f3b88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "257e853d3639423db749699c1f696241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03048ef4a2384bd4b602ef294cfecc56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88f8c08d2e11459a8eda6be724e12e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}